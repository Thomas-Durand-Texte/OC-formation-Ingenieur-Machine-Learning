{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ea1723b",
   "metadata": {},
   "source": [
    "# Nettoyage des données\n",
    "Created by: Thomas Durand-Texte, Jan. 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81c88362",
   "metadata": {},
   "source": [
    "# Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "import missingno as msno\n",
    "\n",
    "import datetime as dt\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import tools\n",
    "cm = 1./2.54\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e00ce8e",
   "metadata": {},
   "source": [
    "# Reload module (for updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f579c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "cm = 1./2.54\n",
    "importlib.reload(tools)\n",
    "tools.set_theme( white_font=True )\n",
    "# tools.plot_test_figure()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7894fe31",
   "metadata": {},
   "source": [
    "# Lecture des premières lignes pour vérifier le format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99973d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('openfood_OC.csv' , 'r') as file:\n",
    "    line = file.readline()\n",
    "    print('n \\\\t: {:}'.format( len(line.split('\\t')) ) )\n",
    "    print(line)\n",
    "    # print(file.readline())\n",
    "    # print(file.readline())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e1187c2",
   "metadata": {},
   "source": [
    "# chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ce362",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = { 'additives': 'object' , 'abbreviated_product_name': 'object', 'allergens': 'object', 'cities_tags': 'object', 'code': 'object', 'ecoscore_grade_fr': 'object', 'emb_codes': 'object', 'emb_codes_tags': 'object', 'first_packaging_code_geo': 'object', 'food_groups': 'object', 'food_groups_en': 'object', 'food_groups_tags': 'object', 'generic_name': 'object', 'ingredients_from_palm_oil_tags': 'object', 'ingredients_that_may_be_from_palm_oil_tags': 'object', 'manufacturing_places': 'object', 'manufacturing_places_tags': 'object', 'origins': 'object', 'origins_en': 'object', 'origins_tags': 'object', 'packaging_text': 'object', 'purchase_places': 'object', 'traces': 'object', 'traces_en': 'object', 'traces_tags': 'object'}\n",
    "data = dd.read_csv('openfood_OC.csv', delimiter ='\\t', dtype=dtype)\n",
    "data = data.compute()\n",
    "\n",
    "# data = pd.read_csv('openfood_OC.csv', delimiter='\\t', dtype=dtype)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "266d0aa6",
   "metadata": {},
   "source": [
    "# Visiualisation of NaN with missingno\n",
    "as barplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3086aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar( data )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9755bbcf",
   "metadata": {},
   "source": [
    "# remove empty and some usused/unusable? columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data) # number of samples\n",
    "sum_isnull = data.isnull().sum() # number of null data for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst of keywords for categories that must be kept\n",
    "keep_keys = ['score', 'origins', 'brands', 'labels', 'allergens', 'additives', 'palm']\n",
    "# lst of keywords for categories that must be dropped\n",
    "drop_keys = ['image', 'url']\n",
    "\n",
    "n_null_lim_drop = int(0.9*n)\n",
    "\n",
    "\n",
    "categories_full = sum_isnull[ sum_isnull == 0].index.to_list()\n",
    "print('\\nFull categories:', categories_full)\n",
    "\n",
    "categories_hollow = sum_isnull[ sum_isnull > n_null_lim_drop].index.to_list()\n",
    "print('\\nHollow categories:', categories_hollow)\n",
    "\n",
    "other_removed_cat = tools.lst_str_keep_items_containing_key( data.keys() , drop_keys )\n",
    "print('\\nother removed categories:', other_removed_cat )\n",
    "\n",
    "removed_cat = tools.lst_str_remove_items_containing_key( categories_hollow + other_removed_cat , keep_keys )\n",
    "\n",
    "# check is completely empty categories remains\n",
    "removed_cat += [ key for key in sum_isnull[ sum_isnull == n].index.to_list() if not key in removed_cat ]\n",
    "\n",
    "# check for dupplicate entry\n",
    "removed_cat = [ key for i, key in enumerate( removed_cat ) if not key in removed_cat[:i] ]\n",
    "\n",
    "# check if key are still in DataFrame\n",
    "removed_cat = [key for key in removed_cat if key in data.keys()]\n",
    "print('\\nRemoved categories:', removed_cat )\n",
    "\n",
    "\n",
    "\n",
    "if True: data.drop( columns=removed_cat, inplace=True )\n",
    "\n",
    "# msno.bar( data )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94cfdb8e",
   "metadata": {},
   "source": [
    "# Visualisation of NaN for new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar( data )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e16b355b",
   "metadata": {},
   "source": [
    "# Heatmap without fully filled categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap( data[ [key for key in data.keys() if (not key in categories_full)] ] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c4e7e9d",
   "metadata": {},
   "source": [
    "# Heatmap without fully filled categories (qualitatives + nutriscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msno.heatmap( data[ [key for key in data.keys() if (not key in categories_full) and (not '_100g' in key) or 'score' in key] ] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d1aabde",
   "metadata": {},
   "source": [
    "# DTYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(data.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae085611",
   "metadata": {},
   "source": [
    "# Listes des catégories: string / float64 / others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_float, categories_others = [], []\n",
    "for cat in data.keys():\n",
    "    if data.dtypes[cat] == 'float64': categories_float.append( cat )\n",
    "    else: categories_others.append( cat )\n",
    "\n",
    "categories_string = []\n",
    "# print('\\nstrings to lowercase')\n",
    "for key in categories_others: \n",
    "    # print(key, 'type', data[key].dtype)\n",
    "    if data[key].dtype != 'object': continue\n",
    "    categories_string.append( key )\n",
    "    data[key].str.lower()\n",
    "\n",
    "print(\"float categories:\", categories_float )\n",
    "print(\"\\nstring categories:\", categories_string )\n",
    "print(\"\\nothers categories:\", categories_others )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f265a6d",
   "metadata": {},
   "source": [
    "# Analyse variables category\n",
    "1. str.lower\n",
    "1. replace unknown in 'pnn_groups'\n",
    "1. astype 'category'\n",
    "1. print first values for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_catergories_to_value_count = ['nova_group', 'nutriscore_grade', 'pnns_groups_1', 'pnns_groups_2', 'food_groups']\n",
    "\n",
    "\n",
    "# lower all string\n",
    "for key in string_catergories_to_value_count:\n",
    "    print(key, data[key].dtype.kind)\n",
    "    # if data[key].dtype.kind != 'O': continue # Check if dtyp is object\n",
    "    if not pd.api.types.is_string_dtype( data[key].dtype ): continue\n",
    "    data[key] = data[key].str.lower()\n",
    "\n",
    "# replace 'unknown' to NaN\n",
    "data.replace( {'pnns_groups_1':'unknown', 'pnns_groups_2':'unknown'}, np.nan, inplace=True )\n",
    "\n",
    "# astype category\n",
    "data[string_catergories_to_value_count] = data[string_catergories_to_value_count].astype('category')\n",
    "\n",
    "\n",
    "for key in string_catergories_to_value_count:\n",
    "    print('\\n', key, data.dtypes[key])\n",
    "    i = 0\n",
    "    for value in data[key] :\n",
    "        if pd.isnull( value ) : continue\n",
    "        print(value )\n",
    "        i += 1\n",
    "        if i == 10: break\n",
    "dico_value_counts = { key: data[key].value_counts().sort_values() for key in string_catergories_to_value_count }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb86ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_value_counts = pd.DataFrame( {key:[len(dico_value_counts[key])] for key in string_catergories_to_value_count} )\n",
    "display(data_value_counts)\n",
    "# data_value_counts.plot( kind='bar' )\n",
    "\n",
    "# print('min counts', data_value_counts.iloc[0,:].min() )\n",
    "\n",
    "for key in string_catergories_to_value_count:\n",
    "    if data_value_counts[key][0] > 50: continue\n",
    "    n_sum = dico_value_counts[key].sum()\n",
    "    fig, ax = plt.subplots()\n",
    "    pd.Series( dico_value_counts[key] ).plot( kind='pie' , ax=ax, autopct='%.1f%%' )\n",
    "    ax.set_title( '{:} ({:} / {:} values)'.format( key, n_sum, n), weight='bold')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "    fig, ax = plt.subplots( figsize=(20*cm, 10*cm*(data_value_counts[key][0]/10)) )\n",
    "    pd.Series( dico_value_counts[key] ).plot( kind='barh' , ax=ax )\n",
    "    ax.set_title(key)\n",
    "\n",
    "if False: # barplot\n",
    "    cat_pos = np.arange( len(string_catergories_to_value_count) )\n",
    "    print(cat_pos)\n",
    "    fig, ax = plt.subplots( figsize=(20*cm,10*cm))\n",
    "    if True: # horizontal\n",
    "        ax.bar( cat_pos, data_value_counts.iloc[0,:] , align='center')\n",
    "        ax.set_xticks(cat_pos, labels=string_catergories_to_value_count)\n",
    "    else:\n",
    "        ax.barh( cat_pos, data_value_counts.iloc[0,:] , align='center')\n",
    "        ax.set_yticks(cat_pos, labels=string_catergories_to_value_count)\n",
    "        ax.invert_yaxis()  # labels read top-to-bottom\n",
    "\n",
    "    fig.tight_layout()\n",
    "    del cat_pos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1564f24",
   "metadata": {},
   "source": [
    "# Analyse variables float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe = data[categories_float].describe()\n",
    "df_describe.boxplot( showfliers=False, vert=False )\n",
    "\n",
    "IQs = df_describe.loc['75%', :] - df_describe.loc['25%', :]\n",
    "\n",
    "\n",
    "# display(IQs)\n",
    "df_describe = pd.concat( (df_describe, IQs.to_frame().T) , ignore_index=False )\n",
    "df_describe.rename( index={0:'IQ'}, inplace=True )\n",
    "display( df_describe )\n",
    "\n",
    "key = 'energy_100g'\n",
    "data.loc[ data[key] > df_describe[key]['75%'] + 1.5*df_describe[key]['IQ'] , key ] = np.nan\n",
    "\n",
    "df_describe = data[categories_float].describe()\n",
    "df_describe.boxplot( showfliers=False, vert=False )\n",
    "display( df_describe )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d67c51a",
   "metadata": {},
   "source": [
    "# Labels\n",
    "Several labels per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'labels_en'\n",
    "\n",
    "print('Example of labels:\\n')\n",
    "i = 0\n",
    "for value in data[key]:\n",
    "        if value is np.nan : continue\n",
    "        print(value)\n",
    "        i += 1\n",
    "        if i == 10: break\n",
    "dico_value_labels = tools.value_count_labels_in_string_series( data.loc[~data[key].isnull(),key] , ',' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de445a2b",
   "metadata": {},
   "source": [
    "# A REGARDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65853d00",
   "metadata": {},
   "source": [
    "df = pd.DataFrame({\"value\": np.random.randint(0, 100, 20)})\n",
    "\n",
    "labels = [\"{0} - {1}\".format(i, i + 9) for i in range(0, 100, 10)]\n",
    "\n",
    "df[\"group\"] = pd.cut(df.value, range(0, 105, 10), right=False, labels=labels)\n",
    "\n",
    "df.head(10)\n",
    "Out[9]: \n",
    "   value    group\n",
    "0     65  60 - 69\n",
    "1     49  40 - 49\n",
    "2     56  50 - 59\n",
    "3     43  40 - 49\n",
    "4     43  40 - 49\n",
    "5     91  90 - 99\n",
    "6     32  30 - 39\n",
    "7     87  80 - 89\n",
    "8     36  30 - 39\n",
    "9      8    0 - 9\n",
    "\n",
    "\n",
    "\n",
    "s.str.contains('foo|bar', na=False, regex=False)\n",
    "# na to manage nan (to False)\n",
    "# regex=False to speed up, when regex-based search is not needed\n",
    "\n",
    "# `axis=1` tells `apply` to apply the lambda function column-wise.\n",
    "df.apply(lambda col: col.str.contains('foo|bar', na=False), axis=1)\n",
    "\n",
    "terms = ['foo', 'baz']\n",
    "df4[df4['col'].str.contains('|'.join(terms))]\n",
    "\n",
    "How do I select by partial string from a pandas DataFrame?\n",
    "This post is meant for readers who want to\n",
    "\n",
    "search for a substring in a string column (the simplest case) as in df1[df1['col'].str.contains(r'foo(?!$)')]\n",
    "search for multiple substrings (similar to isin), e.g., with df4[df4['col'].str.contains(r'foo|baz')]\n",
    "match a whole word from text (e.g., \"blue\" should match \"the sky is blue\" but not \"bluejay\"), e.g., with df3[df3['col'].str.contains(r'\\bblue\\b')]\n",
    "match multiple whole words\n",
    "Understand the reason behind \"ValueError: cannot index with vector containing NA / NaN values\" and correct it with str.contains('pattern',na=False)\n",
    "...and would like to know more about what methods should be preferred over others.\n",
    "\n",
    "(P.S.: I've seen a lot of questions on similar topics, I thought it would be good to leave this here.)\n",
    "\n",
    "Friendly disclaimer, this is post is long.\n",
    "\n",
    "Basic Substring Search\n",
    "# setup\n",
    "df1 = pd.DataFrame({'col': ['foo', 'foobar', 'bar', 'baz']})\n",
    "df1\n",
    "\n",
    "      col\n",
    "0     foo\n",
    "1  foobar\n",
    "2     bar\n",
    "3     baz\n",
    "str.contains can be used to perform either substring searches or regex based search. The search defaults to regex-based unless you explicitly disable it.\n",
    "\n",
    "Here is an example of regex-based search,\n",
    "\n",
    "# find rows in `df1` which contain \"foo\" followed by something\n",
    "df1[df1['col'].str.contains(r'foo(?!$)')]\n",
    "\n",
    "      col\n",
    "1  foobar\n",
    "Sometimes regex search is not required, so specify regex=False to disable it.\n",
    "\n",
    "#select all rows containing \"foo\"\n",
    "df1[df1['col'].str.contains('foo', regex=False)]\n",
    "# same as df1[df1['col'].str.contains('foo')] but faster.\n",
    "   \n",
    "      col\n",
    "0     foo\n",
    "1  foobar\n",
    "Performance wise, regex search is slower than substring search:\n",
    "\n",
    "df2 = pd.concat([df1] * 1000, ignore_index=True)\n",
    "\n",
    "%timeit df2[df2['col'].str.contains('foo')]\n",
    "%timeit df2[df2['col'].str.contains('foo', regex=False)]\n",
    "\n",
    "6.31 ms ± 126 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "2.8 ms ± 241 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Avoid using regex-based search if you don't need it.\n",
    "\n",
    "Addressing ValueErrors\n",
    "Sometimes, performing a substring search and filtering on the result will result in\n",
    "\n",
    "ValueError: cannot index with vector containing NA / NaN values\n",
    "This is usually because of mixed data or NaNs in your object column,\n",
    "\n",
    "s = pd.Series(['foo', 'foobar', np.nan, 'bar', 'baz', 123])\n",
    "s.str.contains('foo|bar')\n",
    "\n",
    "0     True\n",
    "1     True\n",
    "2      NaN\n",
    "3     True\n",
    "4    False\n",
    "5      NaN\n",
    "dtype: object\n",
    "\n",
    "\n",
    "s[s.str.contains('foo|bar')]\n",
    "# ---------------------------------------------------------------------------\n",
    "# ValueError                                Traceback (most recent call last)\n",
    "Anything that is not a string cannot have string methods applied on it, so the result is NaN (naturally). In this case, specify na=False to ignore non-string data,\n",
    "\n",
    "s.str.contains('foo|bar', na=False)\n",
    "\n",
    "0     True\n",
    "1     True\n",
    "2    False\n",
    "3     True\n",
    "4    False\n",
    "5    False\n",
    "dtype: bool\n",
    "How do I apply this to multiple columns at once?\n",
    "The answer is in the question. Use DataFrame.apply:\n",
    "\n",
    "# `axis=1` tells `apply` to apply the lambda function column-wise.\n",
    "df.apply(lambda col: col.str.contains('foo|bar', na=False), axis=1)\n",
    "\n",
    "       A      B\n",
    "0   True   True\n",
    "1   True  False\n",
    "2  False   True\n",
    "3   True  False\n",
    "4  False  False\n",
    "5  False  False\n",
    "All of the solutions below can be \"applied\" to multiple columns using the column-wise apply method (which is OK in my book, as long as you don't have too many columns).\n",
    "\n",
    "If you have a DataFrame with mixed columns and want to select only the object/string columns, take a look at select_dtypes.\n",
    "\n",
    "Multiple Substring Search\n",
    "This is most easily achieved through a regex search using the regex OR pipe.\n",
    "\n",
    "# Slightly modified example.\n",
    "df4 = pd.DataFrame({'col': ['foo abc', 'foobar xyz', 'bar32', 'baz 45']})\n",
    "df4\n",
    "\n",
    "          col\n",
    "0     foo abc\n",
    "1  foobar xyz\n",
    "2       bar32\n",
    "3      baz 45\n",
    "\n",
    "df4[df4['col'].str.contains(r'foo|baz')]\n",
    "\n",
    "          col\n",
    "0     foo abc\n",
    "1  foobar xyz\n",
    "3      baz 45\n",
    "You can also create a list of terms, then join them:\n",
    "\n",
    "terms = ['foo', 'baz']\n",
    "df4[df4['col'].str.contains('|'.join(terms))]\n",
    "\n",
    "          col\n",
    "0     foo abc\n",
    "1  foobar xyz\n",
    "3      baz 45\n",
    "Sometimes, it is wise to escape your terms in case they have characters that can be interpreted as regex metacharacters. If your terms contain any of the following characters...\n",
    "\n",
    ". ^ $ * + ? { } [ ] \\ | ( )\n",
    "Then, you'll need to use re.escape to escape them:\n",
    "\n",
    "import re\n",
    "df4[df4['col'].str.contains('|'.join(map(re.escape, terms)))]\n",
    "\n",
    "          col\n",
    "0     foo abc\n",
    "1  foobar xyz\n",
    "3      baz 45\n",
    "re.escape has the effect of escaping the special characters so they're treated literally.\n",
    "\n",
    "re.escape(r'.foo^')\n",
    "# '\\\\.foo\\\\^'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b430301",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "fig.tight_layout()\n",
    "tools.savefig( fig, 'Figures/test' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "d08940f5c29ec481e2fbf97c73f9a565ba223bd1408f2f48139b80c6375d7776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
