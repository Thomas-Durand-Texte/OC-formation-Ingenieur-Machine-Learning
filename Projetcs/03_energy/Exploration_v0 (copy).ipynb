{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ea1723b",
   "metadata": {},
   "source": [
    "# Exploration des données - feature engineering\n",
    "Created by: Thomas Durand-Texte, Feb. 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81c88362",
   "metadata": {},
   "source": [
    "# Import des packages et données\n",
    "## import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import IndexSlice as idx\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# import dask as dd\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "import datetime as dt\n",
    "import scipy.stats as st\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "import pingouin as pg\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = 1./2.54"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e1187c2",
   "metadata": {},
   "source": [
    "## Paramètres graphiques et fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ce362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "white_font = True\n",
    "def set_theme( white_font=True ):\n",
    "    \"\"\" set_theme( white_font=True ) \"\"\"\n",
    "    if white_font: wht, grey, blck = '0.84' , '0.5', 'k'\n",
    "    else: wht, grey, blck = 'k', '0.5', '0.84'\n",
    "    rc = { 'figure.facecolor':(0.118,)*3,\n",
    "            'axes.labelcolor':wht,\n",
    "            'axes.edgecolor':wht,\n",
    "            'axes.facecolor':(0,0,0,0),\n",
    "            'text.color':'white',\n",
    "            'text.usetex':False,\n",
    "            'text.latex.preamble':r'\\usepackage[cm]{sfmath} \\usepackage{amsmath}' ,\n",
    "            'font.family': 'sans-serif' ,\n",
    "            'font.sans-serif': 'DejaVu Sans' ,\n",
    "            'xtick.color':wht,\n",
    "            'ytick.color':wht,\n",
    "            \"axes.grid\" : True,\n",
    "            \"grid.color\": (0.7,)*3,\n",
    "            \"grid.linewidth\": 0.4,\n",
    "            \"grid.linestyle\": (10,5),\n",
    "            'legend.edgecolor':'0.2',\n",
    "            'legend.facecolor':(0.2,0.2,0.2,0.6),\n",
    "            # 'legend.framealpha':'0.6',\n",
    "            'pdf.fonttype':42,\n",
    "            'savefig.format':'pdf',\n",
    "            'savefig.transparent':True,\n",
    "            'figure.dpi':150, # for better agreemet figsize vs real size\n",
    "        }\n",
    "\n",
    "    base_palette = sns.color_palette()\n",
    "    sns.set_theme( 'notebook' , rc=rc )\n",
    "    sns.set_palette( base_palette )\n",
    "    return\n",
    "\n",
    "\n",
    "def make_folder( path_folder ):\n",
    "    path_folder = path_folder.__str__()\n",
    "    try:\n",
    "        if os.path.isdir( path_folder ) : return\n",
    "        os.makedirs(path_folder)\n",
    "    except OSError:\n",
    "        pass\n",
    "    return\n",
    "\n",
    "def concat_folders(*args, **kwargs):\n",
    "    \"\"\" concat_folders(*args, **kwargs)\n",
    "        concatenate folders in args (strings) \"\"\"\n",
    "    sPath = ''\n",
    "    for arg in args:\n",
    "        if arg == '..': sPath = sPath[:sPath[:-1].rfind(os.sep)+1]\n",
    "        else: sPath += arg\n",
    "        if sPath[-1] != os.sep: sPath += os.sep\n",
    "    return sPath\n",
    "\n",
    "class Path(object):\n",
    "    \"\"\" Path( s_in='', s_lim=None)\n",
    "        create a path to the string s_in (default is current path)\n",
    "        and stops after s_lim \"\"\"\n",
    "    n_Path = 0\n",
    "    def __init__(self, s_in='', s_lim=None):\n",
    "        \"\"\"docstring.\"\"\"\n",
    "        if s_in == '': s_in = os.getcwd()\n",
    "        if not s_lim is None:\n",
    "            if s_lim in s_in:\n",
    "                s_in = s_in[ :s_in.index( s_lim ) + len(s_lim) ]\n",
    "        self.sPath = concat_folders(s_in)\n",
    "        self.N = Path.n_Path\n",
    "        Path.n_Path += 1\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\" Path + str : return str \"\"\"\n",
    "        if isinstance(other, str): return self.sPath + other\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        \"\"\" Path / str : return path concatenated\"\"\"\n",
    "        if isinstance(other, str): return Path(concat_folders(self.sPath, other))\n",
    "\n",
    "    def __invert__(self):\n",
    "        \"\"\" ~Path : return str of the path \"\"\"\n",
    "        return self.sPath\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" __str__ return str of the path \"\"\"\n",
    "        return self.sPath\n",
    "    # __str__ #\n",
    "\n",
    "    def makedir( self ):\n",
    "        return make_folder( self )\n",
    "\n",
    "\n",
    "def gs_opt( filename ):\n",
    "    \"\"\" otpimisation of a pdf file with gosthscript \"\"\"\n",
    "    filenameTmp = filename.replace('.pdf', '') + '_tmp.pdf'\n",
    "    gs = ['gs',\n",
    "            '-sDEVICE=pdfwrite',\n",
    "            '-dEmbedAllFonts=true',\n",
    "            '-dSubsetFonts=true',             # Create font subsets (default)\n",
    "            '-dPDFSETTINGS=/prepress',        # Image resolution\n",
    "            '-dDetectDuplicateImages=true',   # Embeds images used multiple times only once\n",
    "            '-dCompressFonts=true',           # Compress fonts in the output (default)\n",
    "            '-dNOPAUSE',                      # No pause after each image\n",
    "            '-dQUIET',                        # Suppress output\n",
    "            '-dBATCH',                        # Automatically exit\n",
    "            '-sOutputFile='+filenameTmp,      # Save to temporary output\n",
    "            filename]                         # Input file\n",
    "\n",
    "    subprocess.run(gs)                                      # Create temporary file\n",
    "    subprocess.run( 'rm -f ' + filename, shell=True)            # Delete input file\n",
    "    subprocess.run( 'mv -f ' + filenameTmp + \" \" + filename, shell=True) # Rename temporary to input file\n",
    "\n",
    "def savefig( fig, savename, **kwargs ):\n",
    "    \"\"\" savefig( fig, savename, **kwargs )\n",
    "        Saves a figure with kwargs (fig.savefig( savename, **kwargs) ).\n",
    "        A check is done first to determine if a folder has to be created according to savename.\n",
    "        Finally, if the file is saved as .pdf, gosthscript optimisation is performed. \"\"\"\n",
    "    if os.sep in savename: make_folder( savename[:savename.rindex(os.sep)] )\n",
    "    fig.savefig( savename, **kwargs )\n",
    "    savename += '.pdf'\n",
    "    if os.path.isfile( savename ): gs_opt( savename )\n",
    "\n",
    "\n",
    "def image_size_from_width_and_shape( width: float, shape: tuple, ymargin=0. ):\n",
    "    \"\"\" return tuple (width, height) corresponding to image shape \"\"\"\n",
    "    return width, width*shape[0]/shape[1]+ymargin\n",
    "\n",
    "def image_size_from_height_and_shape( height: float, shape: tuple, xmargin=0. ):\n",
    "    \"\"\" return tuple (width, height) corresponding to image shape \"\"\"\n",
    "    return height*shape[1]/shape[0]+xmargin, height\n",
    "\n",
    "\n",
    "set_theme()\n",
    "del set_theme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67db9758",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fca7a85c",
   "metadata": {},
   "source": [
    "Affichage de l'arborescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_listdir( path=None, level=0, exclude=['ressources']) :\n",
    "    suffix = ''\n",
    "    if level > 0:\n",
    "        suffix = ' |-'* level\n",
    "    vals = os.listdir( path )\n",
    "    vals.sort()\n",
    "    if path is None:\n",
    "        path = ''\n",
    "    for val in vals:\n",
    "        if val in exclude: continue\n",
    "        print( suffix, val)\n",
    "        if os.path.isdir( path + val):\n",
    "            print_listdir( path + val + '/', level+1 )\n",
    "\n",
    "print_listdir( exclude=['.venv', 'ressources'] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85cb9fee",
   "metadata": {},
   "source": [
    "1. Chargement des données\n",
    "2. lower strings\n",
    "3. compression et sauvegarde des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac367d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/source/'\n",
    "filename = '2016_Building_Energy_Benchmarking'\n",
    "compression = 'gzip'\n",
    "\n",
    "if True:\n",
    "    df = pd.read_csv( path + filename + '.csv' )\n",
    "    for key in df.keys():\n",
    "        if df[key].dtype == 'object':\n",
    "            df[key] = df[key].str.lower()\n",
    "\n",
    "    # suppression des colonnes vides (ici seulement comments)\n",
    "    df.drop( columns=df.keys()[df.isna().sum(0) == len(df)], inplace=True )\n",
    "\n",
    "    df.to_pickle( r'{:}{:}.pkl'.format(path, filename), compression=compression)\n",
    "else:\n",
    "    df = pd.read_pickle( r'{:}{:}.pkl'.format(path, filename), compression=compression )\n",
    "\n",
    "del compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c5d228f",
   "metadata": {},
   "source": [
    "# 1. Nettoyage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "806b30e8",
   "metadata": {},
   "source": [
    "## 1.1 Initial Filtering : contexte = usage non résidentiel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6103fd2e",
   "metadata": {},
   "source": [
    "value counts des 'BuildingType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f93487",
   "metadata": {},
   "outputs": [],
   "source": [
    "display( df['BuildingType'].value_counts() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1bd8f93",
   "metadata": {},
   "source": [
    "Suppression des Mutlifamily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d36783",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_loc = df['BuildingType'].str.contains('multifamily')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot( df.loc[~sr_loc,'Longitude'], df.loc[~sr_loc,'Latitude'], 'ro', markersize=4, label='residential')\n",
    "ax.plot( df.loc[sr_loc,'Longitude'], df.loc[sr_loc,'Latitude'], 'bo', markersize=4, label='others')\n",
    "ax.legend()\n",
    "ax.axis('equal')\n",
    "ax.set_title('Buildind locations')\n",
    "ax.set_xlabel('Longutide (centered around average)')\n",
    "ax.set_ylabel('Latitude (centered around average)')\n",
    "\n",
    "\n",
    "sr_loc = sr_loc[sr_loc]\n",
    "df.drop( index=sr_loc.index, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "display( df['BuildingType'].value_counts() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30e3592c",
   "metadata": {},
   "source": [
    "Définition d'une fonction pour déterminer les éléments correspondant à du `housing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_housing( sr ):\n",
    "    sr_loc = (sr.str.contains('hous|multifamily', na=False)) \\\n",
    "        & (~sr.str.contains('warehouse|courthouse', na=True))\n",
    "    return sr_loc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e2cbd07",
   "metadata": {},
   "source": [
    "Vérification et suppression à partir du `PrimaryPropertyType`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88331a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'PrimaryPropertyType'\n",
    "sr_loc = is_housing(df[var])\n",
    "display( df.loc[sr_loc, var].value_counts() )\n",
    "df.drop( index=sr_loc[sr_loc].index, inplace=True )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c89e59b",
   "metadata": {},
   "source": [
    "1. Vérification et suppression pour le `LargestPropertyUseType`\n",
    "2. Vérification des LargestPropertyUseType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['LargestPropertyUseType',\n",
    "        'SecondLargestPropertyUseType',\n",
    "        'ThirdLargestPropertyUseType']\n",
    "\n",
    "\n",
    "sr_loc = is_housing( df[vars[0]] )\n",
    "df.drop( index=sr_loc[sr_loc].index, inplace=True )\n",
    "\n",
    "sr_loc = is_housing( df[vars[1]] )\n",
    "for var in vars[2:]:\n",
    "    sr_loc = sr_loc | is_housing( df[var] )\n",
    "\n",
    "# display( df['LargestPropertyUseType'].value_counts() )\n",
    "# display( df['SecondLargestPropertyUseType'].value_counts() )\n",
    "# display( df['ThirdLargestPropertyUseType'].value_counts() )\n",
    "\n",
    "display( f'housing find in {sr_loc.sum()} elements' )\n",
    "display( df.loc[sr_loc, vars] )\n",
    "\n",
    "del vars, var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c5cafde",
   "metadata": {},
   "source": [
    "## 1.2 Outlier et DefaultData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts( sr ):\n",
    "    value_counts = sr.value_counts()\n",
    "    return pd.DataFrame( {'count': value_counts.values, \n",
    "                        '%':value_counts.values*(100/len(sr)) },\n",
    "                        index=value_counts.index)\n",
    "\n",
    "print('Outlier:')\n",
    "display( value_counts( df['Outlier'] ) )\n",
    "print('DefaultData:')\n",
    "display( value_counts( df['DefaultData'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca45eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outlier'] = df['Outlier'].map( {'low outlier':-1, 'high outlier':1}).fillna(0).astype('int')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20b34d84",
   "metadata": {},
   "source": [
    "## 1.3 Vérifications doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of duplicated: {:}\".format( df['OSEBuildingID'].duplicated().sum() ) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c01ceffb",
   "metadata": {},
   "source": [
    "## 1.4 Variables \"inutiles\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61b841e6",
   "metadata": {},
   "source": [
    "Vérification des variables inutiles: création d'une liste \"à supprimer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3af43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_delete = ['OSEBuildingID', 'PropertyName',\n",
    "        'TaxParcelIdentificationNumber',\n",
    "        'CouncilDistrictCode']\n",
    "# df.drop( columns=vars, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a584cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_check = ['DataYear', 'City', 'State']\n",
    "\n",
    "for var in vars_to_check:\n",
    "    if not var in df.keys() :\n",
    "        print( f'{var} not in DataFrame')\n",
    "        continue\n",
    "    sr = df[var].value_counts()\n",
    "    display(sr)\n",
    "    if len(sr) < 2:\n",
    "        # df.drop( columns=var, inplace=True )\n",
    "        vars_to_delete.append( var )\n",
    "        print( f'{var} added to the drop list')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0b325d6",
   "metadata": {},
   "source": [
    "Variable de localité: on prend la variable Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_delete += ['ZipCode', 'Longitude', 'Latitude']\n",
    "\n",
    "mask = 'Neighborhood'\n",
    "display( df[mask].value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df[mask] == 'delridge neighborhoods', mask ] = 'delridge'\n",
    "display( df[mask].value_counts() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9c172fa",
   "metadata": {},
   "source": [
    "## 1.5 Recherche et gestion des NaN\n",
    "### 1.5.1 Détection des NaN\n",
    "- Pour les Second & Third LargestPropertyUseType : uniquement 1 ou 2 utilisation du bâtiment\n",
    "- Pour le YearsENERGYSTARCertified : pas de certification\n",
    "- Pour le ENERGYSTARscore : essayer de le modéliser ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46514b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_isna = df.isna().sum()\n",
    "print( 'sum isna > 0:' )\n",
    "display( sum_isna[sum_isna > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = msno.bar( df )\n",
    "\n",
    "ax = msno.matrix( df.sort_values( by=['SecondLargestPropertyUseType','ThirdLargestPropertyUseType'] ) )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f900b890",
   "metadata": {},
   "source": [
    "Il y a clairement des lignes avec un gros manque d'informations -> à enlever\n",
    "- sur les energy : fillna(0) + sum(1) == 0 -> drop\n",
    "- LargestPropertyUse : à remplir à partir du PrimaryPropertyType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_keys = ['SiteEUI(kBtu/sf)', 'SiteEUIWN(kBtu/sf)',\n",
    "'SourceEUI(kBtu/sf)', 'SourceEUIWN(kBtu/sf)',\n",
    "'SiteEnergyUse(kBtu)', 'SiteEnergyUseWN(kBtu)',\n",
    "'SteamUse(kBtu)', \n",
    "'Electricity(kWh)', 'Electricity(kBtu)',\n",
    "'NaturalGas(therms)', 'NaturalGas(kBtu)',\n",
    "'TotalGHGEmissions', 'GHGEmissionsIntensity']\n",
    "\n",
    "property_use_keys = [ 'PrimaryPropertyType', 'ListOfAllPropertyUseTypes', 'LargestPropertyUseType']\n",
    "\n",
    "others = ['NumberofBuildings']\n",
    "\n",
    "keys = property_use_keys + others + energy_keys\n",
    "\n",
    "sr_loc = df[keys].isna().sum(1) > 0\n",
    "print('Entries with empty cells:')\n",
    "display( df.loc[sr_loc, keys])\n",
    "\n",
    "# DROP DATA WITHOUT ENERGY INFORMATION / CONSUMPTION\n",
    "indexes = (df[energy_keys].fillna(0.).sum(1) == 0.)\n",
    "indexes = indexes[indexes].index\n",
    "print('indexes to drop:', indexes.values)\n",
    "df.drop( index=indexes , inplace=True )\n",
    "\n",
    "print('Entries with empty cells (after drop):')\n",
    "sr_loc = df[keys].isna().sum(1) > 0\n",
    "display( df.loc[sr_loc, keys])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcf19f50",
   "metadata": {},
   "source": [
    "### 1.5.2 Remplissage des NaN\n",
    "On regarde les éléments sans LargestPropertyUseType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ddf074",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['PrimaryPropertyType', 'ListOfAllPropertyUseTypes',\n",
    "        'LargestPropertyUseType', 'LargestPropertyUseTypeGFA', 'PropertyGFABuilding(s)',\n",
    "        'PropertyGFAParking', 'PropertyGFATotal' ]\n",
    "sr_loc = (df['LargestPropertyUseType'].isna())\n",
    "display( df.loc[sr_loc,vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( df.loc[ df['PrimaryPropertyType']==\"self-storage facility\", 'LargestPropertyUseType'].value_counts() )\n",
    "display( df.loc[ df['PrimaryPropertyType'].str.contains('office'), 'LargestPropertyUseType'].value_counts() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a835a23a",
   "metadata": {},
   "source": [
    "À priori on peut replacer les valeurs manquantes de \"LargestPropertyUseType(GFA)\" par la \"PrimaryPropertyType\" / le \"PropertyGFABuilding(s)\".\n",
    "\n",
    "Note: si présence de \"office\" dans le \"PrimaryPropertyType\", alors la valeur est \"office\" (pas de distinctions pour les \"LargestPropertyUseType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef34cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in sr_loc[sr_loc].index:\n",
    "    Primary = df.at[index, 'PrimaryPropertyType']\n",
    "    df.at[index, 'LargestPropertyUseTypeGFA'] = df.at[index, 'PropertyGFABuilding(s)']\n",
    "    if 'office' in Primary:\n",
    "        df.at[index, 'LargestPropertyUseType'] = 'office'\n",
    "        continue\n",
    "    df.at[index, 'LargestPropertyUseType'] = Primary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7c4e8ef",
   "metadata": {},
   "source": [
    "On vérifie le résultat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b575f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display( df.loc[sr_loc,vars] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_isna = df.isna().sum()\n",
    "print( 'sum isna > 0:' )\n",
    "display( sum_isna[sum_isna > 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80d5d356",
   "metadata": {},
   "source": [
    "Remplissage du ZipCode à partir de la longitude et de la latitude: toutes les données étant à Seattle, les variables `Longitude` et `Latitude` peuvent être utilisée comme (`x`,`y`).\n",
    "\n",
    "Si il y avait plus d'écarts entre les positions, possibilité d'utilisé le package `haversine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_loc = df['ZipCode'].isna()\n",
    "for index in sr_loc[sr_loc].index:\n",
    "    x,y = df.loc[index, ['Longitude', 'Latitude']].values\n",
    "    for value in df['Longitude']:\n",
    "        if isinstance( value, str):\n",
    "            print('value:', value)\n",
    "    df['Longitude'].values-x\n",
    "    df['Latitude'].values-y\n",
    "    argsort = ((df['Longitude'].values-x)**2 + (df['Latitude'].values-y)**2).argsort()\n",
    "    for i in argsort[1:]: # neglect the first as it corresponds to the current index\n",
    "        if np.isnan( df['ZipCode'].iloc[i] ) :\n",
    "            continue\n",
    "        df.at[index, 'ZipCode'] = df['ZipCode'].iloc[i]\n",
    "        break \n",
    "    # print('\\nx,y:', x,y, '\\nx2,y2:', df[['Longitude','Latitude']].iloc[i,:].values )\n",
    "\n",
    "sum_isna = df.isna().sum()\n",
    "print( 'After procees sum isna > 0:' )\n",
    "display( sum_isna[sum_isna > 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22b1a57b",
   "metadata": {},
   "source": [
    "***\n",
    "# 2. Vérifications des données d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26d14f77",
   "metadata": {},
   "source": [
    "## 2.1 Value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['BuildingType', 'PrimaryPropertyType',\n",
    "       'Neighborhood', 'NumberofBuildings',\n",
    "       'NumberofFloors', 'LargestPropertyUseType',\n",
    "        'SecondLargestPropertyUseType',\n",
    "        'ThirdLargestPropertyUseType',\n",
    "       ]\n",
    "for var in vars:\n",
    "    print( f'{var} value_counts:')\n",
    "    display( df[var].value_counts() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e471bed",
   "metadata": {},
   "source": [
    "## 2.2 Number of floors\n",
    "On regarde les number of floors pour voir si il y a des valeurs aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 'PropertyGFABuilding(s)', 'NumberofFloors'\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm,12*cm) )\n",
    "ax.plot( df[X], df[Y], 'bo', markersize=3 )\n",
    "\n",
    "ax.set_ylabel( 'Number of floors' )\n",
    "ax.set_xlabel( 'Property GFA buildings (sf)' )\n",
    "\n",
    "index_100 = df[Y] > 90\n",
    "index_100 = index_100[index_100].index.values[0]\n",
    "\n",
    "ax.annotate( 'valeur aberrantes :\\n{:}'.format( \n",
    "                df.at[index_100, 'PropertyName'] ),\n",
    "                xy=[0, 99], xytext=[2.1e6, 82],# ha='left', va='center',\n",
    "                arrowprops=dict(shrink=0.05) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac64e3ed",
   "metadata": {},
   "source": [
    "On assigne la valeur la plus utilisée pour NumberofFloors: 1, sachant que la surface est relativement faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[index_100, Y] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "183e46b1",
   "metadata": {},
   "source": [
    "## 2.3 histogramme / transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ad0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['YearBuilt', 'PropertyGFATotal',\n",
    "       'PropertyGFAParking', 'PropertyGFABuilding(s)',\n",
    "       'LargestPropertyUseTypeGFA', \n",
    "       'SecondLargestPropertyUseTypeGFA', \n",
    "       'ThirdLargestPropertyUseTypeGFA']\n",
    "\n",
    "exponents = [1, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "display( df[vars].describe() )\n",
    "for var, expo in zip(vars, exponents):\n",
    "    values = df[var].dropna()\n",
    "    n_zeros = (values==0).sum()\n",
    "    values = values[values !=0]\n",
    "    kurtosis = st.kurtosis( values )\n",
    "    skew = st.skew( values )\n",
    "\n",
    "    fig, axs = plt.subplots( ncols=2, figsize=(18*cm,8*cm))\n",
    "    fig.suptitle( f'{var}: {n_zeros} zeros'  )\n",
    "    axs[0].hist( values, bins=50 )\n",
    "    axs[0].set_xlabel( 'values'  )\n",
    "    axs[0].set_ylabel( 'count' )\n",
    "    axs[0].set_title( f'skweness: {skew:.3f}, kurtosis: {kurtosis:.3f}')\n",
    "\n",
    "    # values = values**expo\n",
    "    values = np.log(values + 1)\n",
    "    kurtosis = st.kurtosis( values )\n",
    "    skew = st.skew( values )\n",
    "    axs[1].hist( values, bins=50 )\n",
    "    axs[1].set_xlabel( 'log(values+1)' )\n",
    "    axs[1].set_ylabel( 'count' )\n",
    "    axs[1].set_title( f'skweness: {skew:.3f}, kurtosis: {kurtosis:.3f}')\n",
    "\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04eea204",
   "metadata": {},
   "source": [
    "## 2.4 autres vérifications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e006656",
   "metadata": {},
   "source": [
    "Certains `NumberofBuildings` sont particulièrement élevés, mais à priori OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = 'NumberofBuildings'\n",
    "df.loc[ df[mask] > 5, :].sort_values( by=mask )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b6e95e3",
   "metadata": {},
   "source": [
    "Signification `NumberofFLoors` == 0 ? pas d'étage ?\n",
    "\n",
    "Pour la `seattle chinese baptist church` 99 floors n'est pas cohérent (surtout en regardant l'image satellite): elle a donc été remplacée par 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = 'NumberofFloors'\n",
    "df.sort_values( by=mask, ascending=False ).iloc[:10,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1edbd2f5",
   "metadata": {},
   "source": [
    "PorpertyGFA : outliers ?\n",
    "\n",
    "`university of washington - seattle campus` et `entire campus` correspondent à des valeurs `atypique` mais non aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = 'PropertyGFATotal'\n",
    "describe = df[mask].describe()\n",
    "print(mask)\n",
    "display(describe)\n",
    "\n",
    "print('Q3 + 1.5*IQ = {:.3e}'.format( describe['75%'] \n",
    "            + 1.5*(describe['75%']-describe['25%']) ) )\n",
    "\n",
    "df.sort_values( by=mask, ascending=False ).iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef37220",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = 'PropertyGFAParking'\n",
    "describe = df[mask].describe()\n",
    "print(mask)\n",
    "display(describe.T)\n",
    "df.sort_values( by=mask, ascending=False ).iloc[:5,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43744f92",
   "metadata": {},
   "source": [
    "## 2.5 Categories \"LargestPropertyUseType\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42ca251e",
   "metadata": {},
   "source": [
    "Liste des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319815e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp = pd.DataFrame( {'A':['a','a','b','c','c','c'],\n",
    "                    'B':['b','b','c','d','d','e']})\n",
    "display( tmp['A'].value_counts() )\n",
    "display( tmp['B'].value_counts() )\n",
    "display( tmp['A'].value_counts().add( tmp['B'].value_counts() , fill_value=0 ).astype(int)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LargestPropertyUseType'].value_counts().add(\n",
    "    df['SecondLargestPropertyUseType'].value_counts(), fill_value=0 ).add(\n",
    "    df['ThirdLargestPropertyUseType'].value_counts(), fill_value=0 ).astype(int).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d43ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['LargestPropertyUseType'].str.contains('other - entertainment/public assembly', na=False), 'PropertyName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = ['LargestPropertyUseType','SecondLargestPropertyUseType', 'ThirdLargestPropertyUseType']\n",
    "for mask in masks:\n",
    "    display( df.loc[df[mask].str.contains('recreation', na=False), mask].value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_keys = [ ('store', ['wholesale', 'mall', 'store', 'dealership'] ),\n",
    "                    ('utility', ['fire', 'utility', 'police', 'courthouse', 'prison', 'bank']),\n",
    "                    ('restaurant', ['food', 'restaurant']),\n",
    "                    ('residential - hotel', ['residential', 'housing', 'hotel', 'dormitory']),\n",
    "                    ('education', ['school', 'education', 'university']),\n",
    "                    ('medical', ['care', 'hospital']),\n",
    "                    ('office', ['financial office']),\n",
    "                    ('entertainment/public assembly', ['theater','nightclub',\n",
    "                                'recreation', 'swimming', 'performing arts',\n",
    "                                'library','museum','meeting hall']),\n",
    "                    ('lifestyle center', ['lifestyle', 'fitness']),\n",
    "                    ('science', ['technology', 'laboratory']),\n",
    "                    ('services', ['services'])\n",
    "             ]\n",
    "for (category,keys) in categories_keys :\n",
    "    joint_keys = '|'.join(keys)\n",
    "    for mask in masks:\n",
    "        sr_loc = df[mask].str.contains( joint_keys , na=False )\n",
    "        df.loc[ sr_loc, mask ] = category\n",
    "\n",
    "\n",
    "value_counts = df['LargestPropertyUseType'].value_counts().add(\n",
    "    df['SecondLargestPropertyUseType'].value_counts(), fill_value=0 ).add(\n",
    "    df['ThirdLargestPropertyUseType'].value_counts(), fill_value=0 ).astype(int).sort_values()\n",
    "\n",
    "print( f'{len(value_counts)} categories')\n",
    "display( value_counts )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf411a11",
   "metadata": {},
   "source": [
    "## 2.6 Year-built -> categories ?\n",
    "à priori pas de relation directe évidente -> on peut séparer en plusieurs groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6950e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 'YearBuilt', 'SiteEUIWN(kBtu/sf)'\n",
    "\n",
    "print('min:', df[X].min(), 'max:', df[X].max() )\n",
    "print( np.arange( 1900, 2020, 20 ) )\n",
    "\n",
    "bins_yearbuilt = [1900, 1920, 1934, 1943, 1960, 1980, 2000, 2020]\n",
    "df['YearBuiltCateg'] = np.digitize( df[X], bins_yearbuilt )\n",
    "display( df[[X, 'YearBuiltCateg']].sample(10) )\n",
    "\n",
    "x = df[X].values\n",
    "x.sort()\n",
    "diff_x = x[1:]-x[:-1]\n",
    "b_break = diff_x > 1\n",
    "print( 'breaks begin at:', x[:-1][ b_break ])\n",
    "print( 'breaks end at:', x[1:][ b_break ])\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm,6*cm) )\n",
    "ax.plot( x[1:], diff_x, 'bo', markersize=3 )\n",
    "ax.plot( x[1:][ b_break ], diff_x[ b_break ], 'ro', markersize=3 )\n",
    "ax.set_xlabel(X)\n",
    "ax.set_ylabel( 'year difference' )\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm,12*cm) )\n",
    "ax.plot( df[X], df[Y], 'bo', markersize=3 )\n",
    "ax_twinx = ax.twinx()\n",
    "ax_twinx.plot( df[X], df['YearBuiltCateg'], 'yo', markersize=3 )\n",
    "\n",
    "ax.set_xlabel( X )\n",
    "ax.set_ylabel( Y )\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a440a9dc",
   "metadata": {},
   "source": [
    "***\n",
    "# 3. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.select_dtypes(include=[np.number])\n",
    "features = [col for col in tmp.columns if not col in vars_to_delete]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features].dropna()\n",
    "scaler_pca = preprocessing.StandardScaler()\n",
    "X_scaled = scaler_pca.fit_transform(X) # fit and transform\n",
    "idx = [\"mean\", \"std\"]\n",
    "display( pd.DataFrame(X_scaled).describe().round(2).loc[idx, :] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = X_scaled.shape[1]\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# entrainement\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = range(1, n_components+1)\n",
    "scree = (pca.explained_variance_ratio_*100)\n",
    "print('scree:', scree.round(2))\n",
    "print('sum scree:', scree.sum().round(2))\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm))\n",
    "ax.bar( x_list, scree )\n",
    "ax.set_xlabel(\"rang de l'axe d'inertie\")\n",
    "ax.set_ylabel(\"inertie (%)\")\n",
    "ax.set_title('Éboulis des valeurs propres')\n",
    "\n",
    "ax = ax.twinx()\n",
    "ax.set_ylabel(\"inertie (%)\")\n",
    "\n",
    "ax.plot( x_list, scree.cumsum(), c='r', marker='o', label='intertie cumulée')\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout(pad=0.2)\n",
    "# tools.savefig( fig, 'Figures/PCA/ebouli.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "822a392f",
   "metadata": {},
   "source": [
    "La variable `EnergySTARscore` n'impacte que peu les 6 premiers composantes de la PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595cfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pd.DataFrame( pca.components_.transpose() )\n",
    "pcs.index = features\n",
    "columns = [f\"F{i}\" for i in x_list]\n",
    "pcs.columns = columns\n",
    "\n",
    "for i in range(6):\n",
    "    key = f'F{i+1:}'\n",
    "    display( pcs[[key]].sort_values( key, ascending=False ).T )\n",
    "\n",
    "display( pcs.iloc[:,:6].round(2).T ) #.sort_values(by=indexes , ascending=False) )\n",
    "fig, ax = plt.subplots(figsize=(26*cm, 12*cm))\n",
    "sns.heatmap(pcs.iloc[:,:6].T*100, vmin=-100, vmax=100, annot=True, cmap=\"coolwarm\", fmt=\"0.0f\", annot_kws={\"size\": 8})\n",
    "# fig.tight_layout( pad=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b556d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_graph(pca,\n",
    "                      ij_F,\n",
    "                      features,\n",
    "                      ax=None) :\n",
    "    \"\"\"Affiche le graphe des correlations\n",
    "\n",
    "    Positional arguments :\n",
    "    -----------------------------------\n",
    "    pca : sklearn.decomposition.PCA : notre objet PCA qui a été fit\n",
    "    ij_F : list ou tuple : le couple x,y des plans à afficher, exemple [0,1] pour F1, F2\n",
    "    features : list ou tuple : la liste des features (ie des dimensions) à représenter\n",
    "    ax : axis sur lequel le graphique est tracé (default None -> est créé)\n",
    "    \"\"\"\n",
    "\n",
    "    # Extrait x et y\n",
    "    x,y=ij_F\n",
    "\n",
    "    # Taille de l'image (en inches)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 9))\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "\n",
    "    # Pour chaque composante :\n",
    "    for i in range(0, pca.components_.shape[1]):\n",
    "\n",
    "        # Les flèches\n",
    "        ax.arrow(0,0,\n",
    "                pca.components_[x, i],\n",
    "                pca.components_[y, i],\n",
    "                head_width=0.07,\n",
    "                head_length=0.07,\n",
    "                width=0.02, )\n",
    "\n",
    "        # Les labels\n",
    "        ax.text(pca.components_[x, i] + 0.05*np.sign(pca.components_[x, i]),\n",
    "                pca.components_[y, i] + 0.05*np.sign(pca.components_[y, i]),\n",
    "                features[i])\n",
    "\n",
    "    # Affichage des lignes horizontales et verticales\n",
    "    ax.plot([-1, 1], [0, 0], color='grey', ls='--', zorder=0)\n",
    "    ax.plot([0, 0], [-1, 1], color='grey', ls='--', zorder=0)\n",
    "\n",
    "    # Nom des axes, avec le pourcentage d'inertie expliqué\n",
    "    ax.set_xlabel('F{} ({}%)'.format(x+1, round(100*pca.explained_variance_ratio_[x],1)))\n",
    "    ax.set_ylabel('F{} ({}%)'.format(y+1, round(100*pca.explained_variance_ratio_[y],1)))\n",
    "\n",
    "    # J'ai copié collé le code sans le lire\n",
    "    ax.set_title(\"Cercle des corrélations (F{} et F{})\".format(x+1, y+1))\n",
    "\n",
    "    # Le cercle\n",
    "    an = np.linspace(0, 2 * np.pi, 100)\n",
    "    ax.plot(np.cos(an), np.sin(an), zorder=0 )  # Add a unit circle for scale\n",
    "\n",
    "    # Axes et display\n",
    "    ax.axis('equal')\n",
    "    plt.show(block=False)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4eabe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    fig, ax = plt.subplots( figsize=(14*cm, 12*cm))\n",
    "    \n",
    "    correlation_graph( pca, [i+i,i+i+1], features, ax=ax )\n",
    "    fig.tight_layout( )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c19d6cd",
   "metadata": {},
   "source": [
    "***\n",
    "# 4. Target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70987e80",
   "metadata": {},
   "source": [
    "Présence de valeurs incohérentes (0 != sum autres variables) pour `SiteEUIWN(kBtu/sf)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79a6192e",
   "metadata": {},
   "source": [
    "On regarde les dates des relevés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211322f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display( df['DataYear'].value_counts() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e2024a7",
   "metadata": {},
   "source": [
    "Toutes les mesures ont été faites la même année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 'SiteEUI(kBtu/sf)', 'SiteEUIWN(kBtu/sf)'\n",
    "fig, ax = plt.subplots( figsize=(8*cm,8*cm))\n",
    "ax.plot( df[X], df[Y], 'bo', markersize=3 )\n",
    "ax.set_xlabel(X)\n",
    "ax.set_ylabel(Y)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adc69cc1",
   "metadata": {},
   "source": [
    "- `SiteEUI(kBtu/sf)` est basée sur les factures\n",
    "- `SourceEUI(kbtu/sf)` : \"the annual energy used to operate the property, including losses from generation, transmission, & distribution.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 'SiteEUI(kBtu/sf)', 'SourceEUI(kBtu/sf)'\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit( df[X].values.reshape(-1,1), df[Y] )\n",
    "print( f'estmated coefficient: {lr.coef_[0]:.3f}' )\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(8*cm,8*cm))\n",
    "ax.plot( df[X], df[Y], 'bo', markersize=3 )\n",
    "\n",
    "x = np.array([0, df[X].max()]).reshape(2,1)\n",
    "ax.plot( x, lr.predict(x), 'r' )\n",
    "ax.set_xlabel(X)\n",
    "ax.set_ylabel(Y)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d27e4b2d",
   "metadata": {},
   "source": [
    "Vérification de conversion kWh -> Btu : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a66144",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 'Electricity(kWh)', 'Electricity(kBtu)'\n",
    "coef = 3.412142 # in [Btu] / [Wh]\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit( df[X].values.reshape(-1,1), df[Y] )\n",
    "print( f'estmated coefficient: {lr.coef_[0]:.3f}, theoretical: {coef:}' )\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(8*cm,8*cm))\n",
    "ax.plot( df[X], df[Y], 'bo' )\n",
    "ax.set_xlabel(X)\n",
    "ax.set_ylabel(Y)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d121c349",
   "metadata": {},
   "source": [
    "Vérification de conversion therms -> Btu : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968655e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 'NaturalGas(therms)', 'NaturalGas(kBtu)'\n",
    "coef = 1e2 # in [kBtu]/[therms]\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit( df[X].values.reshape(-1,1), df[Y] )\n",
    "print( f'estmated coefficient: {lr.coef_[0]:.3f}, theoretical: {coef:}' )\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(8*cm,8*cm))\n",
    "ax.plot( df[X], df[Y], 'bo' )\n",
    "ax.set_xlabel(X)\n",
    "ax.set_ylabel(Y)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d59cbe7c",
   "metadata": {},
   "source": [
    "Vérification de la somme des ressources utilisées, <span style=\"color:red\"> variations dues à ?? </span>\n",
    "\n",
    "`SiteEnergyUse(kBtu)` :The annual amount of energy consumed by the property from all sources of energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030df4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = ['SteamUse(kBtu)', 'Electricity(kBtu)', 'NaturalGas(kBtu)'], 'SiteEnergyUse(kBtu)'\n",
    "\n",
    "X_values = df[X].sum(1)\n",
    "diff = X_values - df[Y]\n",
    "\n",
    "display( pd.DataFrame( {Y:df[Y], 'sum ressources':X_values} ).describe().T )\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm))\n",
    "ax.plot( X_values, df[Y], 'bo', markersize=4 )\n",
    "ax.set_xlabel(r'$\\sum$ steam,elec.,gas')\n",
    "ax.set_ylabel(Y)\n",
    "\n",
    "ax_twinx = ax.twinx()\n",
    "ax_twinx.plot( X_values, np.abs(diff) / X_values * 100, 'ro', markersize=4 )\n",
    "ax_twinx.set_ylabel('difference (%)', color='r')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2b66f8a",
   "metadata": {},
   "source": [
    "On regarde à quoi correspondent les surfaces\n",
    "\n",
    "Il y a clairement des incohérences entre les `LargestPropertyUseTypeGFA` et (`PropertyGFATotal`, `PropertyGFABuilding(s)`, `PropertyGFAParking`, `NumberofFloors`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbe499",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['LargestPropertyUseTypeGFA',\n",
    "        'SecondLargestPropertyUseTypeGFA',\n",
    "        'ThirdLargestPropertyUseTypeGFA']].fillna(0.).sum(1)\n",
    "# X = df['LargestPropertyUseTypeGFA']\n",
    "\n",
    "\n",
    "Y1 = 'PropertyGFABuilding(s)'\n",
    "Y2 = 'PropertyGFAParking'\n",
    "\n",
    "Y = 'PropertyGFATotal'\n",
    "y = df[Y]\n",
    "\n",
    "# sr_loc = df['LargestPropertyUseType'] != 'parking'\n",
    "# x = X.loc[sr_loc]\n",
    "# y = y.loc[sr_loc]\n",
    "\n",
    "# Y = 'GFA Building(s) + parking'\n",
    "# y = df[Y1] + df[Y2]\n",
    "\n",
    "# y = df['PropertyGFABuilding(s)'] * ( df['NumberofFloors'] +1 ) + df['PropertyGFAParking']\n",
    "# Y = 'Surface à voir'\n",
    "\n",
    "# diff = X - df[Y]\n",
    "# display( pd.DataFrame( {Y:df[Y], 'sum surfaces':X_values} ).describe().T )\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm))\n",
    "ax.plot( x, y, 'bo', markersize=2 )\n",
    "ax.plot( [0, y.max()], [0, y.max()], 'r', zorder=0 )\n",
    "# ax.plot( [0,y.max()], [0,y.max()], 'r', label='ideal match' )\n",
    "# ax.legend()\n",
    "\n",
    "ax.set_xlabel(r'$\\sum$ PrincipalUseTypeGFA')\n",
    "ax.set_ylabel(Y)\n",
    "\n",
    "# ax_twinx = ax.twinx()\n",
    "# ax_twinx.plot( X_values, np.abs(diff) / X_values * 100, 'ro', markersize=4 )\n",
    "# ax_twinx.set_ylabel('difference (%)', color='r')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.keys().tolist())\n",
    "X, Y = 'SiteEnergyUse(kBtu)', 'SiteEUI(kBtu/sf)'\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(16*cm,8*cm))\n",
    "X_values = df[X] / y\n",
    "diff = X_values - df[Y]\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit( X_values.values.reshape(-1,1), df[Y] )\n",
    "# print( f'\\nEstmated coefficient: {lr.coef_[0]:.3f}, ideal: {1:}' )\n",
    "\n",
    "display( pd.DataFrame( {Y:df[Y], 're-calculated':X_values} ).describe().T )\n",
    "\n",
    "ymax = df[Y].max()\n",
    "xmax = X_values.max()\n",
    "ax.set_title( f'coef.: {lr.coef_[0]:.3f}' )\n",
    "ax.plot( [0,xmax], [0,xmax], 'r', label='ideal ratio' )\n",
    "ax.plot( [0,xmax], lr.predict( np.array([0,xmax]).reshape(-1,1) ), 'y', label='estimated ratio' )\n",
    "ax.plot( X_values, df[Y], 'bo', markersize=4 )\n",
    "ax.set_xlabel( X + '\\n/\\n(estimated surface)')\n",
    "ax.set_ylabel(Y)\n",
    "ax.legend()\n",
    "\n",
    "# ax_twinx = ax.twinx()\n",
    "# ax_twinx.plot( X_values, np.abs(diff) / X_values * 100, 'ro', markersize=4 )\n",
    "# ax_twinx.set_ylabel('difference (%)', color='r')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f06a9bb2",
   "metadata": {},
   "source": [
    "On prend la valeur \"Weather Normalize\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42600bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'SiteEnergyUseWN(kBtu)'\n",
    "sources = ['NaturalGas(kBtu)', 'Electricity(kBtu)',\n",
    "            'SteamUse(kBtu)']\n",
    "\n",
    "sr_0 = (df[target] == 0) | (df[target].isna())\n",
    "print('number of elements target == 0 | isna:', (sr_0).sum())\n",
    "# display( df.loc[sr_0,:])\n",
    "\n",
    "y = df[target]\n",
    "x = df[ sources ].fillna(0.).sum(1)\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm))\n",
    "ax.plot( x.loc[sr_0], y.loc[sr_0], 'yo', label='0 / NaN target')\n",
    "ax.plot( [0, 4e8], [0,4e8], 'r', zorder=1 )\n",
    "ax.annotate('x = y', [2.5e8, 2.3e8], va='center', ha='left', color='r')\n",
    "\n",
    "ax.plot( x, y , 'bo', markersize=3 )\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67934bde",
   "metadata": {},
   "source": [
    "Calcul des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target] = x\n",
    "\n",
    "sr_0 = (df[target] == 0) | (df[target].isna())\n",
    "print('number of elements target == 0 | isna:', (sr_0).sum())\n",
    "display( df.loc[sr_0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[sr_0,target] = df.loc[sr_0, 'SiteEnergyUse(kBtu)']\n",
    "\n",
    "sr_0 = (df[target] == 0) | (df[target].isna())\n",
    "print('number of elements target == 0 | isna:', (sr_0).sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2c1a430",
   "metadata": {},
   "source": [
    "Il y a un batiment (une \"green structure\") qui produit sa propre énergie et, à priori, plus que nécessaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ee56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_neg = df[target] < 0\n",
    "\n",
    "display( df.loc[sr_neg,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c73248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df[target].values\n",
    "\n",
    "print( ( y + (1-y.min()) ).min() )\n",
    "y_log = np.log( y + (1-y.min() ) )\n",
    "\n",
    "fig, axs = plt.subplots( ncols=2, figsize=(16*cm,8*cm) )\n",
    "n, bins, _ = axs[0].hist( y, bins=50 )\n",
    "n, bins, _ = axs[1].hist( y_log, bins=50 )\n",
    "axs[0].set_xlabel(target )\n",
    "axs[1].set_xlabel( f'log( {target} )' )\n",
    "\n",
    "axs[0].set_title( r'$\\gamma_1$: {:.3f}, $\\gamma_2$: {:.3f}'.format( st.skew(y), st.kurtosis(y) ) )\n",
    "axs[1].set_title( r'$\\gamma_1$: {:.3f}, $\\gamma_2$: {:.3f}'.format( st.skew(y_log), st.kurtosis(y_log) ) )\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "log_target_bins_center = (bins[:-1] + bins[1:]) * 0.5 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26eaed21",
   "metadata": {},
   "source": [
    "## Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xs = ['PropertyGFABuilding(s)', 'LargestPropertyUseTypeGFA']\n",
    "hues = ['PrimaryPropertyType', 'LargestPropertyUseType']\n",
    "\n",
    "# df[target]\n",
    "\n",
    "Y = 'SiteEUIWN(kBtu/sf)'\n",
    "\n",
    "sr_loc = (df[Y] != 0)\n",
    "for X in Xs:\n",
    "    sr_loc = sr_loc & (df[X]!=0)\n",
    "tmp = df.loc[sr_loc, Xs + hues + [Y, 'Outlier']]\n",
    "# tmp = df[[X,target, 'Outlier', hue]]\n",
    "\n",
    "if True:\n",
    "    # tmp[ Xs[1] ] /= tmp[ Xs[0] ]\n",
    "    # sr_loc = tmp[Xs[1]] > 0.7\n",
    "    sr_loc = tmp[hues[0]].str.contains('office')\n",
    "    tmp = tmp.loc[sr_loc,:]\n",
    "\n",
    "\n",
    "for X,hue in zip( Xs, hues ):\n",
    "    g = sns.pairplot( data=tmp, vars=[X,Y], hue=hue,\n",
    "        plot_kws={'s':6} )\n",
    "    \n",
    "    handles = g._legend_data.values()\n",
    "    labels = g._legend_data.keys()\n",
    "    g.fig.legend(handles=handles, labels=labels, loc=[0.2,0.65], ncol=1)\n",
    "\n",
    "    g.fig.suptitle('linear values')\n",
    "    g.fig.tight_layout()\n",
    "    \n",
    "\n",
    "    tmp[X] = np.log( tmp[X] )\n",
    "    tmp[Y] = np.log( tmp[Y] )\n",
    "    g = sns.pairplot( data=tmp, vars=[X,Y], hue=hue,\n",
    "        plot_kws={'s':6} )\n",
    "    # g.legend(bbox_to_anchor= (1.03, 1) )\n",
    "    handles = g._legend_data.values()\n",
    "    labels = g._legend_data.keys()\n",
    "    g.fig.legend(handles=handles, labels=labels, loc=[0.35,0.65], ncol=1)\n",
    "    g.legend.remove()\n",
    "    g.fig.suptitle('log values')\n",
    "    g.fig.tight_layout()\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA( df, hue, Y, transform=None ):\n",
    "    groups = df[[Y,hue]].dropna().groupby(hue)[Y]\n",
    "    index = pd.MultiIndex.from_tuples( [('shape','skew'), ('shape','kurtosis'),('shapiro','statistic'), ('shapiro','p-value')] )\n",
    "    df_shape = pd.DataFrame( index = index)\n",
    "    names = [name for name,yi in groups]\n",
    "    for name, yi in groups:\n",
    "        if not transform is None:\n",
    "            yi = transform( yi )\n",
    "        # print('\\nname:', name)\n",
    "        # print( st.skew(yi) )\n",
    "        # print( st.kurtosis(yi) )\n",
    "        # print( st.shapiro(yi) )\n",
    "        # sr = pd.Series( [  ] ).astype(float)\n",
    "        shapiro = st.shapiro(yi)\n",
    "        df_shape[name] = [st.skew(yi), st.kurtosis(yi), shapiro.statistic, shapiro.pvalue]\n",
    "    \n",
    "    display(df_shape.round(3))\n",
    "\n",
    "    levene = pg.homoscedasticity( df.dropna(), dv=Y, group=hue )\n",
    "    display( levene )\n",
    "\n",
    "    # tpl = tuple( [df.query( f'{hue} == \"{name}\"')[Y].dropna() for name in names ] )\n",
    "    # print( st.levene( *tpl ) )\n",
    "    \n",
    "\n",
    "    display( pg.pairwise_tukey( dv=Y, between=hue, data=df.dropna() ) )\n",
    "\n",
    "    # for i, (name,yi) in enumerate(groups):\n",
    "    #     print('\\n\\n| {:} |\\n\\n'.format( '-'*20 ))\n",
    "    #     if i+1 == len(names):\n",
    "    #         break\n",
    "    #     print(f'name: {name}')\n",
    "    #     for j, (name_2,yi2) in enumerate(groups):\n",
    "    #         if j <= i:\n",
    "    #             continue\n",
    "    #         print( f'\\n{name} - {name_2}:' )\n",
    "    #         stat, p = st.levene(yi, yi2)\n",
    "    #         print( f'levene stat: {stat:.3f}, p-value: {p:.3f}' )\n",
    "    #         print('std: {:.3f} - {:.3f}'.format( yi.std(), yi2.std() ) )\n",
    "print('linear')\n",
    "ANOVA( tmp, 'PrimaryPropertyType', 'SiteEUIWN(kBtu/sf)' )\n",
    "# print('log')\n",
    "# ANOVA( tmp, 'PrimaryPropertyType', 'SiteEUIWN(kBtu/sf)', lambda y:np.log( y + (1-y.min())) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93ec4503",
   "metadata": {},
   "source": [
    "Les \"office\" semblent être des \"small\" offices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = \"PrimaryPropertyType\"\n",
    "df.loc[ df[mask] == 'office', mask] = 'small- and mid-sized office'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad1b920f",
   "metadata": {},
   "source": [
    "Levene test:\n",
    "- `Null Hypothesis`: the `variances` are `equal` across all samples/groups\n",
    "- `Alternative Hypothesis`:  the `variances` are `not equal` across all samples/groups\n",
    "\n",
    "TODO: \n",
    "- Mesure kurosis \n",
    "- skewness\n",
    "- scipy.stats.shapiro(x)\n",
    "\n",
    "The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution.\n",
    "\n",
    "Parameters:\n",
    "xarray_like\n",
    "Array of sample data.\n",
    "\n",
    "Returns:\n",
    "statisticfloat\n",
    "The test statistic.\n",
    "\n",
    "p-valuefloat\n",
    "The p-value for the hypothesis test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87e4353e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f482313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "x = stats.norm.rvs(loc=5, scale=3, size=100, random_state=rng)\n",
    "shapiro_test = stats.shapiro(x)\n",
    "shapiro_test\n",
    "ShapiroResult(statistic=0.9813305735588074, pvalue=0.16855233907699585)\n",
    "shapiro_test.statistic\n",
    "0.9813305735588074\n",
    "shapiro_test.pvalue\n",
    "0.16855233907699585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea94cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xs = ['PropertyGFABuilding(s)', 'LargestPropertyUseTypeGFA']\n",
    "hues = ['PrimaryPropertyType', 'LargestPropertyUseType']\n",
    "\n",
    "# df[target]\n",
    "\n",
    "\n",
    "sr_loc = (df[target] != 0)\n",
    "for X in Xs:\n",
    "    sr_loc = sr_loc & (df[X]!=0)\n",
    "tmp = df.loc[sr_loc, Xs + hues + [target, 'Outlier']]\n",
    "# tmp = df[[X,target, 'Outlier', hue]]\n",
    "\n",
    "if True:\n",
    "    # tmp[ Xs[1] ] /= tmp[ Xs[0] ]\n",
    "    # sr_loc = tmp[Xs[1]] > 0.7\n",
    "    sr_loc = tmp[hues[0]].str.contains('office')\n",
    "    tmp = tmp.loc[sr_loc,:]\n",
    "\n",
    "describe = tmp.groupby(mask).describe()\n",
    "display( describe.loc[ :, idx[:, ['mean', 'std']  ] ].round(2) )\n",
    "\n",
    "# Levene's test\n",
    "mask = 'PrimaryPropertyType'\n",
    "# tpl = tuple( [ tmp.query('{:} == \"{:}\"'.format( mask, grp ) ) for grp in tmp[mask].unique() ] )\n",
    "# tpl_grps = ( tmp.query( '{:} == \"{:}\"'.format( mask, grp ) for grp in tmp[mask].unique() ) )\n",
    "\n",
    "levene = pg.homoscedasticity( tmp, dv=target, group=mask )\n",
    "display( levene )\n",
    "print(f'equal var hypothesis validated : {levene.iloc[0,2]}')\n",
    "\n",
    "for X,hue in zip( Xs, hues ):\n",
    "    break\n",
    "    sns.pairplot( data=tmp, vars=[X,target], hue=hue,\n",
    "        plot_kws={'s':3} )\n",
    "\n",
    "    tmp[X] = np.log( tmp[X] )\n",
    "    tmp[target] = np.log( tmp[target] )\n",
    "    sns.pairplot( data=tmp, vars=[X,target], hue=hue,\n",
    "        plot_kws={'s':3} )\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7ac1cd9",
   "metadata": {},
   "source": [
    "# Analyse des features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c28be374",
   "metadata": {},
   "source": [
    "## utilisation \"office\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0faa04f4",
   "metadata": {},
   "source": [
    "On regarde les différents types d'utilisation `office`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars =['PrimaryPropertyType',\n",
    "        'LargestPropertyUseType']\n",
    "        # ,\n",
    "        # 'SecondLargestPropertyUseType',\n",
    "        # 'ThirdLargestPropertyUseType']\n",
    "\n",
    "sr_loc = df[vars[0]].str.contains('office', na=False)\n",
    "\n",
    "for var in vars:\n",
    "    sr_loc = sr_loc | df[var].str.contains('office', na=False)\n",
    "\n",
    "for var in vars:\n",
    "    print(f'{var}:')\n",
    "    display( df.loc[sr_loc,var].value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots( figsize=(16*cm,20*cm), nrows=6, sharex=True)\n",
    "axs_2 = [axs[0] , axs[2], axs[3], axs[4], axs[5], axs[1] ]\n",
    "df.loc[sr_loc, :].plot.hist( ax=axs_2, column=[target], by='PrimaryPropertyType' , bins=50 )\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( nrows=3, sharex=True)\n",
    "df.loc[sr_loc, :].plot.hist( ax=ax, column=[target], by='LargestPropertyUseType' , bins=50 )\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4599d31",
   "metadata": {},
   "source": [
    "À priori, il est possible de regrouper tous les type d'`offices` ensemble: il y a peut de \"financial\" et \"medical\" offices, et ne semblet pas créer de mode singulièrement différent du mode principale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dfb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars =['PrimaryPropertyType',\n",
    "        'LargestPropertyUseType',\n",
    "        'SecondLargestPropertyUseType',\n",
    "        'ThirdLargestPropertyUseType']\n",
    "\n",
    "for var in vars:\n",
    "    sr_loc = df[var].str.contains( 'office', na=False )\n",
    "    df.loc[sr_loc, var] = 'office'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b67d930",
   "metadata": {},
   "source": [
    "# Date and location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c051e4",
   "metadata": {},
   "source": [
    "## City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871744a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['City', 'State', 'ZipCode',\n",
    "            'DataYear', 'YearBuilt', \n",
    "            'CouncilDistrictCode', 'Neighborhood',\n",
    "            'Latitude', 'Longitude']:\n",
    "    display( df[key].value_counts() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63c2d8a9",
   "metadata": {},
   "source": [
    "La variable city n'est pas utile car elle ne présente qu'une unique valeur: seattle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['City', 'State', 'DataYear']\n",
    "df = df.drop( columns=col_to_drop )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d3c08d5",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f906821",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df['Longitude'], df['Latitude']\n",
    "x -= x.mean()\n",
    "y -= y.mean()\n",
    "values = np.log( df[target] )\n",
    "\n",
    "sr_loc = df['LargestPropertyUseType'] == 'office'\n",
    "x, y, values = x[sr_loc], y[sr_loc], values[sr_loc]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "scttr = ax.scatter( x, y , s=3, c=values )\n",
    "plt.colorbar( scttr , label=target + ' (log)' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8696f209",
   "metadata": {},
   "source": [
    "ANOVA Zipcode - energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ccfa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def ANOVA(x,y):\n",
    "    moyenne_y = y.mean()\n",
    "    classes = {}\n",
    "    for classe in x.unique():\n",
    "        yi_classe = y[x==classe]\n",
    "        ymean_class = yi_classe.mean()\n",
    "        n_i = len(yi_classe)\n",
    "        classes[classe] = {'n_i': n_i,\n",
    "                        'moyenne_classe': ymean_class,\n",
    "                        's_i': (yi_classe**2).sum() - n_i*ymean_class**2 }\n",
    "    k = len(classes) # number of condittions\n",
    "    N = len(y) # number of values\n",
    "\n",
    "    # Degree of Freedom (DF)\n",
    "    DFbetween = k - 1\n",
    "    DFwithin = N - k\n",
    "    DFtotal = N - 1\n",
    "\n",
    "    # Sum of Squares (SS)\n",
    "    SStotal = (y**2).sum() - N*moyenne_y**2\n",
    "    SSbetween = sum([c['n_i']*(c['moyenne_classe']-moyenne_y)**2 for c in classes.values()])\n",
    "    SSwithin = sum( [c['s_i'] for c in classes.values()] )\n",
    "\n",
    "    # Meas Square\n",
    "    MSbetween = SSbetween/DFbetween\n",
    "    MSwithin = SSwithin/DFwithin\n",
    "\n",
    "    F = MSbetween/MSwithin\n",
    "    p = stats.f.sf( F, DFbetween, DFwithin )\n",
    "    eta_sqrd = SSbetween/SStotal\n",
    "\n",
    "    omega_sqrd = (SSbetween - (DFbetween * MSwithin))/(SStotal + MSwithin)\n",
    "\n",
    "    return F,p, eta_sqrd, omega_sqrd, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = 'ZipCode', target\n",
    "df_tmp = df[[X,Y]].dropna()\n",
    "\n",
    "df_describe = df_tmp[[Y]].describe()\n",
    "\n",
    "# Q3 + 1.5*IQ\n",
    "vlim = df_describe[Y]['75%']*2.5 - 1.5*df_describe[Y]['25%']\n",
    "print('Q3 + 1.5*IQ: {:.2f}'.format( vlim ))\n",
    "\n",
    "# ommition des valeurs abérrantes\n",
    "df_tmp = df_tmp.loc[df[Y] < vlim, :]\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "df_describe = pd.concat((df_describe.T, df_tmp[[Y]].describe().T))\n",
    "df_describe.index = ['before crop', 'after crop']\n",
    "\n",
    "display( df_describe.round(3) )\n",
    "\n",
    "F,p, eta_sqrd, omega_sqrd, classes = ANOVA( df_tmp[X], df_tmp[Y] )\n",
    "\n",
    "print( f'F: {F:.3f},', 'p', p, 'eta_sqrd', eta_sqrd, 'omega_sqrd', omega_sqrd)\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "print('columns:', df_tmp.columns)\n",
    "# help( ols )\n",
    "# mod = ols( Y + ' ~ ' + X, data=df_tmp).fit()\n",
    "                \n",
    "# aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "# aov_table[['eta_sqrd', 'omega_sqrd']] = np.nan\n",
    "# aov_table.loc[ X, 'eta_sqrd' ] = eta_sqrd\n",
    "# aov_table.loc[ X, 'omega_sqrd' ] = omega_sqrd\n",
    "# display( aov_table )\n",
    "# print( tools.df2ltx(aov_table.round(3)) )\n",
    "\n",
    "print('eta_sqrd: {:.3f}'.format( eta_sqrd ) )\n",
    "\n",
    "\n",
    "\n",
    "props = {'color':'w', 'linewidth':2}\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm, 8*cm) )\n",
    "df_tmp.boxplot( column=Y, by=X, ax=ax, sym='bo', \n",
    "            boxprops=props, whiskerprops=props,\n",
    "            capprops=props, medianprops=props,\n",
    "            widths=0.5)\n",
    "ax.set_ylabel(Y.replace('_100g', ' (%)'))\n",
    "ax.set_xlabel(X.replace('_', ' '))\n",
    "# ax.set_title(r'$\\eta^2={{{:.3f}}}$'.format(eta_sqrd))\n",
    "ax.set_title('')\n",
    "fig.suptitle(None)\n",
    "fig.tight_layout( pad=1 )\n",
    "# tools.savefig( fig, 'Figures/ANOVA/boxes.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94456624",
   "metadata": {},
   "source": [
    "## Tax Parcel IdentificationNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df198163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TaxParcelIdentificationNumber'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c4c74f6",
   "metadata": {},
   "source": [
    "Vérification doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OSEBuildingID'].duplicated().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8aa62575",
   "metadata": {},
   "source": [
    "***\n",
    "# Définition d'un dataset \"numérique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = pd.DataFrame()\n",
    "features = ['Longitude', 'Latitude', 'YearBuilt',\n",
    "        'NumberofBuildings', 'NumberofFloors',\n",
    "        'PropertyGFATotal', 'PropertyGFAParking']\n",
    "df_num[features] = df[features].values\n",
    "\n",
    "df_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea09adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_0 = df['LargestPropertyUseType'].unique()\n",
    "arr_1 = df['SecondLargestPropertyUseType'].unique()\n",
    "arr_2 = df['ThirdLargestPropertyUseType'].unique()\n",
    "\n",
    "arr = np.concatenate( (arr_0, arr_1, arr_2 ))\n",
    "print(arr.size)\n",
    "PropertyUseTypes = [val for i, val in enumerate(arr) if (not val in arr[:i]) & ~isinstance(val, float)]\n",
    "print( len(PropertyUseTypes) )\n",
    "X_PropertyUseTypeGFA = np.zeros( (len(df), len(PropertyUseTypes)) )\n",
    "for i, index in enumerate(df.index):\n",
    "    for suffix in ['','Second','Third']:\n",
    "        usetype = df.at[index, suffix + 'LargestPropertyUseType']\n",
    "        if isinstance( usetype, float): # test if isnan\n",
    "            break\n",
    "        j = PropertyUseTypes.index( usetype )\n",
    "        X_PropertyUseTypeGFA[i,j] += df.at[index, 'LargestPropertyUseTypeGFA']\n",
    "\n",
    "features += ['GFA ' + usetype for usetype in PropertyUseTypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb24052",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack( (df_num.values,X_PropertyUseTypeGFA) )\n",
    "y = df[target]\n",
    "sr_loc = ~(y.isna()) & (y != 0)\n",
    "\n",
    "X = X[sr_loc.values]\n",
    "y = np.log( y.values[sr_loc.values] )\n",
    "\n",
    "def bin_to_class( val, bins ):\n",
    "    for i, bin in enumerate(bins):\n",
    "        if val < bin:\n",
    "            return i\n",
    "    return len(bins) \n",
    "y_classes = np.array([ bin_to_class( val, log_target_bins_center ) for val in y ])\n",
    "\n",
    "indexes = sr_loc[sr_loc].index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f3c3ae8",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deafc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_pca = preprocessing.StandardScaler()\n",
    "X_scaled = scaler_pca.fit_transform(X) # fit and transform\n",
    "idx = [\"mean\", \"std\"]\n",
    "display( pd.DataFrame(X_scaled).describe().round(2).loc[idx, :] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = X_scaled.shape[1]\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# entrainement\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53669998",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = range(1, n_components+1)\n",
    "scree = (pca.explained_variance_ratio_*100)\n",
    "print('scree:', scree.round(2))\n",
    "print('sum scree:', scree.sum().round(2))\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm))\n",
    "ax.bar( x_list, scree )\n",
    "ax.set_xlabel(\"rang de l'axe d'inertie\")\n",
    "ax.set_ylabel(\"inertie (%)\")\n",
    "ax.set_title('Éboulis des valeurs propres')\n",
    "\n",
    "ax = ax.twinx()\n",
    "ax.set_ylabel(\"inertie (%)\")\n",
    "\n",
    "ax.plot( x_list, scree.cumsum(), c='r', marker='o', label='intertie cumulée')\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout(pad=0.2)\n",
    "# tools.savefig( fig, 'Figures/PCA/ebouli.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb29ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pd.DataFrame( pca.components_.transpose() )\n",
    "pcs.index = features\n",
    "columns = [f\"F{i}\" for i in x_list]\n",
    "pcs.columns = columns\n",
    "\n",
    "for i in range(20):\n",
    "    key = f'F{i+1:}'\n",
    "    display( pcs[[key]].sort_values( key, ascending=False ).T )\n",
    "\n",
    "display( pcs.round(2).T ) #.sort_values(by=indexes , ascending=False) )\n",
    "fig, ax = plt.subplots(figsize=(18*cm, 8*cm))\n",
    "sns.heatmap(pcs.T, vmin=-1, vmax=1, annot=True, cmap=\"coolwarm\", fmt=\"0.2f\")\n",
    "fig.tight_layout( pad=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406159b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_graph(pca,\n",
    "                      ij_F,\n",
    "                      features,\n",
    "                      ax=None) :\n",
    "    \"\"\"Affiche le graphe des correlations\n",
    "\n",
    "    Positional arguments :\n",
    "    -----------------------------------\n",
    "    pca : sklearn.decomposition.PCA : notre objet PCA qui a été fit\n",
    "    ij_F : list ou tuple : le couple x,y des plans à afficher, exemple [0,1] pour F1, F2\n",
    "    features : list ou tuple : la liste des features (ie des dimensions) à représenter\n",
    "    ax : axis sur lequel le graphique est tracé (default None -> est créé)\n",
    "    \"\"\"\n",
    "\n",
    "    # Extrait x et y\n",
    "    x,y=ij_F\n",
    "\n",
    "    # Taille de l'image (en inches)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 9))\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "\n",
    "    # Pour chaque composante :\n",
    "    for i in range(0, pca.components_.shape[1]):\n",
    "\n",
    "        # Les flèches\n",
    "        ax.arrow(0,0,\n",
    "                pca.components_[x, i],\n",
    "                pca.components_[y, i],\n",
    "                head_width=0.07,\n",
    "                head_length=0.07,\n",
    "                width=0.02, )\n",
    "\n",
    "        # Les labels\n",
    "        ax.text(pca.components_[x, i] + 0.05*np.sign(pca.components_[x, i]),\n",
    "                pca.components_[y, i] + 0.05*np.sign(pca.components_[y, i]),\n",
    "                features[i])\n",
    "\n",
    "    # Affichage des lignes horizontales et verticales\n",
    "    ax.plot([-1, 1], [0, 0], color='grey', ls='--', zorder=0)\n",
    "    ax.plot([0, 0], [-1, 1], color='grey', ls='--', zorder=0)\n",
    "\n",
    "    # Nom des axes, avec le pourcentage d'inertie expliqué\n",
    "    ax.set_xlabel('F{} ({}%)'.format(x+1, round(100*pca.explained_variance_ratio_[x],1)))\n",
    "    ax.set_ylabel('F{} ({}%)'.format(y+1, round(100*pca.explained_variance_ratio_[y],1)))\n",
    "\n",
    "    # J'ai copié collé le code sans le lire\n",
    "    ax.set_title(\"Cercle des corrélations (F{} et F{})\".format(x+1, y+1))\n",
    "\n",
    "    # Le cercle\n",
    "    an = np.linspace(0, 2 * np.pi, 100)\n",
    "    ax.plot(np.cos(an), np.sin(an), zorder=0 )  # Add a unit circle for scale\n",
    "\n",
    "    # Axes et display\n",
    "    ax.axis('equal')\n",
    "    plt.show(block=False)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    fig, ax = plt.subplots( figsize=(14*cm, 12*cm))\n",
    "    \n",
    "    correlation_graph( pca, [i+i,i+i+1], features, ax=ax )\n",
    "    fig.tight_layout( )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d60caa68",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "_, _, i_train, i_test = model_selection.train_test_split( range(len(y)) , \n",
    "                                    range(len(y)), train_size=0.8)\n",
    "\n",
    "X_train = X[i_train, :]\n",
    "X_test = X[i_test, :]\n",
    "y_train = y_classes[i_train]\n",
    "y_test = y_classes[i_test]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# help( RandomForestClassifier )\n",
    "rfc = RandomForestClassifier( n_estimators=100, n_jobs=-1, oob_score=True )\n",
    "rfc.fit( X_train, y_train )\n",
    "\n",
    "pred = rfc.predict(X_test)\n",
    "print(\"accuracy: {:.2f}%\".format(100* metrics.accuracy_score(y_test, pred)) )\n",
    "print('score: {:.2f}'.format( 100*rfc.score( X_test, y_test) ))\n",
    "\n",
    "argsort = y_test.argsort()\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot( pred[argsort], 'o' )\n",
    "ax.plot( y_test[argsort], 'r' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# X_train = X[i_train, :]\n",
    "# X_test = X[i_test, :]\n",
    "y_train = y[i_train]\n",
    "y_test = y[i_test]\n",
    "\n",
    "\n",
    "rfr = RandomForestRegressor( n_estimators=100, n_jobs=-1, oob_score=True )\n",
    "rfr.fit( X_train, y_train )\n",
    "print(\"score: {:.2f}\".format(100* rfr.score(X_test, y_test)) )\n",
    "y_pred = rfr.predict( X_test )\n",
    "# help( rfr.score )\n",
    "\n",
    "argsort = y_test.argsort()\n",
    "fig, axs = plt.subplots(nrows=2)\n",
    "axs[0].plot( y_pred[argsort], 'o' )\n",
    "axs[0].plot( y_test[argsort], 'r' )\n",
    "\n",
    "y_train = np.exp( y_train )\n",
    "y_test = np.exp( y_test )\n",
    "\n",
    "rfr = RandomForestRegressor( n_estimators=100, n_jobs=-1, oob_score=True )\n",
    "rfr.fit( X_train, y_train )\n",
    "print(\"score: {:.2f}\".format(100* rfr.score(X_test, y_test)) )\n",
    "y_pred = rfr.predict( X_test )\n",
    "\n",
    "axs[1].semilogy( y_pred[argsort], 'o' )\n",
    "axs[1].plot( y_test[argsort], 'r' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b64fb3e",
   "metadata": {},
   "source": [
    "***\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87365ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_X = ['BuildingType', 'PrimaryPropertyType',\n",
    "        'ZipCode', 'TaxParcelIdentificationNumber',\n",
    "        'CouncilDistrictCode', 'Neighborhood',\n",
    "        'Latitude', 'Longitude',\n",
    "        'YearBuilt', 'NumberofBuildings',\n",
    "        'NumberofFloors', 'PropertyGFATotal',\n",
    "        'PropertyGFAParking', 'PropertyGFABuilding(s)',\n",
    "        'LargestPropertyUseType', 'LargestPropertyUseTypeGFA',\n",
    "        'SecondLargestPropertyUseType', 'SecondLargestPropertyUseTypeGFA',\n",
    "        'ThirdLargestPropertyUseType', 'ThirdLargestPropertyUseTypeGFA'\n",
    "        ]\n",
    "\n",
    "\n",
    "X = df[vars_X].copy()\n",
    "keys = [ 'LargestPropertyUseType', 'SecondLargestPropertyUseType',\n",
    "        'ThirdLargestPropertyUseType' ]\n",
    "\n",
    "X[ keys ] = X[keys].fillna( 'None' )\n",
    "\n",
    "keys = [ 'LargestPropertyUseTypeGFA', 'SecondLargestPropertyUseTypeGFA',\n",
    "        'ThirdLargestPropertyUseTypeGFA' ]\n",
    "X[ keys ] = X[keys].fillna( 0. )\n",
    "\n",
    "display( X.isna().sum())\n",
    "y = df[target].copy()\n",
    "\n",
    "def bin_to_class( val, bins ):\n",
    "    for i, bin in enumerate(bins):\n",
    "        if val < bin:\n",
    "            return i\n",
    "    return len(bins) \n",
    "y_classes = pd.Series( [ bin_to_class( val, log_target_bins_center ) for val in y ] , index=y.index )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "_, _, index_train, index_test = model_selection.train_test_split( range(len(df)) , \n",
    "                                    X.index, train_size=0.8)\n",
    "\n",
    "X_train = X.loc[index_train, :]\n",
    "X_test = X.loc[index_test, :]\n",
    "y_train = y_classes.loc[index_train]\n",
    "y_test = y_classes.loc[index_test]\n",
    "\n",
    "help( RandomForestClassifier )\n",
    "rfc = RandomForestClassifier( n_estimators=100, n_jobs=-1, oob_score=True )\n",
    "rfc.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d24800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "_, _, index_train, index_test = model_selection.train_test_split( range(len(df)) , \n",
    "                                    X.index, train_size=0.8)\n",
    "\n",
    "X_train = X.loc[index_train, :]\n",
    "X_test = X.loc[index_test, :]\n",
    "y_train = y.loc[index_train]\n",
    "y_test = y.loc[index_test]\n",
    "\n",
    "rfr = RandomForestRegressor( n_estimators=100, n_jobs=-1, oob_score=True )\n",
    "rfr.fit( X_train, y_train )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc53148c",
   "metadata": {},
   "source": [
    "# Quels types d'utilisation ?\n",
    "- il est probablement préférable de ne garder que le `PrimaryPropertyType`\n",
    "- il y a une `incohérence` dans le tri `large` | `small- or mid-sized` office : les histrogrammes se recoupent\n",
    "- <span style=\"color:red\"> residence hall/domitory ? </span>\n",
    "- <span style=\"color:red\"> LargestPropertyUseType : other - lodging/residential ? </span>\n",
    "- <span style=\"color:red\"> Faut-il faire quelques groupes ? Offiche + others ? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['PrimaryPropertyType',\n",
    "        'LargestPropertyUseType',\n",
    "        'SecondLargestPropertyUseType',\n",
    "        'ThirdLargestPropertyUseType']\n",
    "\n",
    "for var in vars:\n",
    "    value_counts = df[var].value_counts()\n",
    "    display( value_counts )\n",
    "    fig, ax = plt.subplots()\n",
    "    value_counts.plot( kind='pie' , ax=ax, autopct='%.1f%%' )\n",
    "    ax.set_title( var )\n",
    "    ax.set_ylabel('')\n",
    "    fig.tight_layout(pad=0.2)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "print('small- and mid-sized office')\n",
    "sr_loc = df[vars[0]].str.contains('mid-sized office')\n",
    "display( df.loc[sr_loc, ['LargestPropertyUseTypeGFA'] ].describe() )\n",
    "\n",
    "values_small_med = np.log( df.loc[sr_loc, 'LargestPropertyUseTypeGFA' ].values )\n",
    "\n",
    "\n",
    "var_surf = 'LargestPropertyUseTypeGFA'\n",
    "\n",
    "print('large office')\n",
    "sr_loc = df[vars[0]].str.contains('large office')\n",
    "display( df.loc[sr_loc, [var_surf] ].describe() )\n",
    "\n",
    "values_large = np.log( df.loc[sr_loc, var_surf] )\n",
    "\n",
    "ax.hist( [values_small_med, values_large],\n",
    "        bins=50, label=['small- and mid-sized', 'large'] )\n",
    "\n",
    "ax.plot([],[], 'r', label='size not referenced')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('histogram of the surface used as office')\n",
    "\n",
    "sr_loc = df[vars[0]] == 'office'\n",
    "for value in df.loc[sr_loc, var_surf]:\n",
    "    ax.plot( [np.log(value),]*2, [0,10] , 'r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7543ee1",
   "metadata": {},
   "source": [
    "## Observation office size - targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['TotalGHGEmissions']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "494689f2acac87956b2fb49f164ea5a9a6b259eda3b61e1868bcc936735ce35f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
