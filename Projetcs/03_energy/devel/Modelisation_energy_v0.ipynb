{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68cf100a",
   "metadata": {},
   "source": [
    "# NOTEBOOK NAME\n",
    "Created by: Thomas Durand-Texte, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des packages et données\n",
    "## import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import dask as dd\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "import datetime as dt\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn import model_selection, metrics, preprocessing, linear_model, dummy\n",
    "from sklearn import svm\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = 1./2.54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramètres graphiques et fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "white_font = True\n",
    "def set_theme( white_font=True ):\n",
    "    \"\"\" set_theme( white_font=True ) \"\"\"\n",
    "    if white_font: wht, grey, blck = '0.84' , '0.5', 'k'\n",
    "    else: wht, grey, blck = 'k', '0.5', '0.84'\n",
    "    rc = { 'figure.facecolor':(0.118,)*3,\n",
    "            'axes.labelcolor':wht,\n",
    "            'axes.edgecolor':wht,\n",
    "            'axes.facecolor':(0,0,0,0),\n",
    "            'text.color':'white',\n",
    "            'text.usetex':False,\n",
    "            'text.latex.preamble':r'\\usepackage[cm]{sfmath} \\usepackage{amsmath}' ,\n",
    "            'font.family': 'sans-serif' ,\n",
    "            'font.sans-serif': 'DejaVu Sans' ,\n",
    "            'xtick.color':wht,\n",
    "            'ytick.color':wht,\n",
    "            \"axes.grid\" : True,\n",
    "            \"grid.color\": (0.7,)*3,\n",
    "            \"grid.linewidth\": 0.4,\n",
    "            \"grid.linestyle\": (10,5),\n",
    "            'legend.edgecolor':'0.2',\n",
    "            'legend.facecolor':(0.2,0.2,0.2,0.6),\n",
    "            # 'legend.framealpha':'0.6',\n",
    "            'pdf.fonttype':42,\n",
    "            'savefig.format':'pdf',\n",
    "            'savefig.transparent':True,\n",
    "            'figure.dpi':150, # for better agreemet figsize vs real size\n",
    "        }\n",
    "\n",
    "    sns.set_theme( 'notebook' , rc=rc )\n",
    "    return\n",
    "\n",
    "\n",
    "def make_folder( path_folder ):\n",
    "    path_folder = path_folder.__str__()\n",
    "    try:\n",
    "        if os.path.isdir( path_folder ) : return\n",
    "        os.makedirs(path_folder)\n",
    "    except OSError:\n",
    "        pass\n",
    "    return\n",
    "\n",
    "def concat_folders(*args, **kwargs):\n",
    "    \"\"\" concat_folders(*args, **kwargs)\n",
    "        concatenate folders in args (strings) \"\"\"\n",
    "    sPath = ''\n",
    "    for arg in args:\n",
    "        if arg == '..': sPath = sPath[:sPath[:-1].rfind(os.sep)+1]\n",
    "        else: sPath += arg\n",
    "        if sPath[-1] != os.sep: sPath += os.sep\n",
    "    return sPath\n",
    "\n",
    "class Path(object):\n",
    "    \"\"\" Path( s_in='', s_lim=None)\n",
    "        create a path to the string s_in (default is current path)\n",
    "        and stops after s_lim \"\"\"\n",
    "    n_Path = 0\n",
    "    def __init__(self, s_in='', s_lim=None):\n",
    "        \"\"\"docstring.\"\"\"\n",
    "        if s_in == '': s_in = os.getcwd()\n",
    "        if not s_lim is None:\n",
    "            if s_lim in s_in:\n",
    "                s_in = s_in[ :s_in.index( s_lim ) + len(s_lim) ]\n",
    "        self.sPath = concat_folders(s_in)\n",
    "        self.N = Path.n_Path\n",
    "        Path.n_Path += 1\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\" Path + str : return str \"\"\"\n",
    "        if isinstance(other, str): return self.sPath + other\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        \"\"\" Path / str : return path concatenated\"\"\"\n",
    "        if isinstance(other, str): return Path(concat_folders(self.sPath, other))\n",
    "\n",
    "    def __invert__(self):\n",
    "        \"\"\" ~Path : return str of the path \"\"\"\n",
    "        return self.sPath\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" __str__ return str of the path \"\"\"\n",
    "        return self.sPath\n",
    "    # __str__ #\n",
    "\n",
    "    def makedir( self ):\n",
    "        return make_folder( self )\n",
    "\n",
    "\n",
    "def gs_opt( filename ):\n",
    "    \"\"\" otpimisation of a pdf file with gosthscript \"\"\"\n",
    "    filenameTmp = filename.replace('.pdf', '') + '_tmp.pdf'\n",
    "    gs = ['gs',\n",
    "            '-sDEVICE=pdfwrite',\n",
    "            '-dEmbedAllFonts=true',\n",
    "            '-dSubsetFonts=true',             # Create font subsets (default)\n",
    "            '-dPDFSETTINGS=/prepress',        # Image resolution\n",
    "            '-dDetectDuplicateImages=true',   # Embeds images used multiple times only once\n",
    "            '-dCompressFonts=true',           # Compress fonts in the output (default)\n",
    "            '-dNOPAUSE',                      # No pause after each image\n",
    "            '-dQUIET',                        # Suppress output\n",
    "            '-dBATCH',                        # Automatically exit\n",
    "            '-sOutputFile='+filenameTmp,      # Save to temporary output\n",
    "            filename]                         # Input file\n",
    "\n",
    "    subprocess.run(gs)                                      # Create temporary file\n",
    "    subprocess.run( 'rm -f ' + filename, shell=True)            # Delete input file\n",
    "    subprocess.run( 'mv -f ' + filenameTmp + \" \" + filename, shell=True) # Rename temporary to input file\n",
    "\n",
    "def savefig( fig, savename, **kwargs ):\n",
    "    \"\"\" savefig( fig, savename, **kwargs )\n",
    "        Saves a figure with kwargs (fig.savefig( savename, **kwargs) ).\n",
    "        A check is done first to determine if a folder has to be created according to savename.\n",
    "        Finally, if the file is saved as .pdf, gosthscript optimisation is performed. \"\"\"\n",
    "    if os.sep in savename: make_folder( savename[:savename.rindex(os.sep)] )\n",
    "    fig.savefig( savename, **kwargs )\n",
    "    savename += '.pdf'\n",
    "    if os.path.isfile( savename ): gs_opt( savename )\n",
    "\n",
    "\n",
    "def image_size_from_width_and_shape( width: float, shape: tuple, ymargin=0. ):\n",
    "    \"\"\" return tuple (width, height) corresponding to image shape \"\"\"\n",
    "    return width, width*shape[0]/shape[1]+ymargin\n",
    "\n",
    "def image_size_from_height_and_shape( height: float, shape: tuple, xmargin=0. ):\n",
    "    \"\"\" return tuple (width, height) corresponding to image shape \"\"\"\n",
    "    return height*shape[1]/shape[0]+xmargin, height\n",
    "\n",
    "\n",
    "set_theme()\n",
    "del set_theme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f823eb2",
   "metadata": {},
   "source": [
    "Affichage de l'arborescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_listdir( path=None, level=0, exclude=[] ) :\n",
    "    suffix = ''\n",
    "    if level > 0:\n",
    "        suffix = ' |-'* level\n",
    "    vals = os.listdir( path )\n",
    "    vals.sort()\n",
    "    if path is None:\n",
    "        path = ''\n",
    "    for val in vals:\n",
    "        if val in exclude: continue\n",
    "        print( suffix, val)\n",
    "        if os.path.isdir( path + val):\n",
    "            print_listdir( path + val + '/', level+1 )\n",
    "\n",
    "print_listdir( exclude=['.venv', 'ressources'] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85cb9fee",
   "metadata": {},
   "source": [
    "Chargement / compression des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac367d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/cleaned/'\n",
    "filename = '2016_Building_Energy_Benchmarking'\n",
    "compression = 'gzip'\n",
    "\n",
    "df = pd.read_pickle( r'{:}{:}.pkl'.format(path, filename), compression=compression )\n",
    "\n",
    "filename = 'other_data.pkl'\n",
    "with open( path + filename , 'rb' ) as file:\n",
    "    features_1,features_2, features_3,features_4, \\\n",
    "    PropertyUseTypes, \\\n",
    "    X_propotion_PropertyUseTypeGFA, X_ParkingGFA,\\\n",
    "    X_propotion_energy = pickle.load( file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f93487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('features_1:\\n', features_1)\n",
    "print('\\nfeatures_2:\\n', features_2)\n",
    "print('\\nfeatures_3:\\n', features_3)\n",
    "print('\\nfeatures_4:\\n', features_4)\n",
    "\n",
    "target = features_2[2]\n",
    "y = df[target].values\n",
    "\n",
    "# y /= df['PropertyGFABuilding(s)'].values\n",
    "\n",
    "y_add_transform = (1.-y.min() )\n",
    "y = np.log( y + y_add_transform )\n",
    "\n",
    "str_out = f'log( {target} )'\n",
    "\n",
    "i_nan = np.isnan( y.ravel() )\n",
    "for Xi in [X_propotion_PropertyUseTypeGFA, X_ParkingGFA, X_propotion_energy]:\n",
    "    i_nan = i_nan & ( np.isnan( Xi ).reshape(y.size, -1).max(1) )\n",
    "print( '\\nNumber of NaN: {:}'.format( i_nan.sum() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis = st.kurtosis( y )\n",
    "skew = st.skew( y )\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "ax.hist( y, bins=30 )\n",
    "ax.set_xlabel( f'log( {target} )' )\n",
    "ax.set_title( f'skweness: {skew:.3f}, kurtosis: {kurtosis:.3f}')\n",
    "\n",
    "y2 = y[(y>1) & (y<7)]\n",
    "kurtosis = st.kurtosis( y2 )\n",
    "skew = st.skew( y2 )\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "ax.hist( y2, bins=30 )\n",
    "ax.set_xlabel( str_out )\n",
    "ax.set_title( f'skweness: {skew:.3f}, kurtosis: {kurtosis:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( model_name, model, param_grid, score='r2' ): \n",
    "    # Créer un classifieur kNN avec recherche d'hyperparamètre par validation croisée\n",
    "    modelCV = model_selection.GridSearchCV(\n",
    "        model, # modèle\n",
    "        param_grid,     # hyperparamètres à tester\n",
    "        cv=5,           # nombre de folds de validation croisée\n",
    "        scoring=score,   # score à optimiser\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    modelCV.fit(X_train, y_train)\n",
    "    model_to_results( model_name, modelCV, X_test, time.time()-t0 )\n",
    "\n",
    "    return modelCV\n",
    "\n",
    "def log_transfrom( x ):\n",
    "    return np.log( x + ( 1. - min([0, x.min()]) ) )\n",
    "\n",
    "def print_coefs( coefs, features ):\n",
    "    n_features_0 = len( features )\n",
    "\n",
    "    print('coefficients linear:')\n",
    "    print(coefs[:n_features_0])\n",
    "\n",
    "    if len( coefs ) > n_features_0:\n",
    "        print('coefficients non-linear:')\n",
    "        print(coefs[n_features_0:])\n",
    "\n",
    "    print('linear coefs == 0 for :') #, np.array(features)[ coefs[:n_features_0+1] == 0. ])\n",
    "    print('[', end='')\n",
    "    for feature in np.array(features)[ coefs[:n_features_0] == 0. ]:\n",
    "        print( f\"'{feature}', \", end='')\n",
    "    print(']')\n",
    "\n",
    "    if len( coefs ) > n_features_0+1:\n",
    "        print('non-linear coefs == 0 for :', np.array(features[1:])[ coefs[n_features_0+1:] == 0. ])\n",
    "\n",
    "def histogram_per_coef( X, coefs, features ):\n",
    "    y = (X @ coefs.reshape(-1,1)).ravel()\n",
    "    for xi, coef, feature in zip( X.transpose(), coefs, features):\n",
    "        fig, ax = plt.subplots( figsize=(12*cm,8*cm))\n",
    "        ax.hist( xi*(coef*100)/y, bins=50 )\n",
    "        ax.set_ylabel('count')\n",
    "        ax.set_xlabel('influence sur la cible (%)')\n",
    "        ax.set_title(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e721ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_GFA_building = df['PropertyGFABuilding(s)'].values.reshape(-1,1)\n",
    "X_GFA_parking = X_ParkingGFA.reshape(-1,1)\n",
    "\n",
    "if True:\n",
    "    key = ['Neighborhood', 'ZipCode'][0]\n",
    "    df[key] = df[key].astype('category')\n",
    "    print( df[key].cat.categories )\n",
    "    features_location = df[key].cat.categories.tolist()\n",
    "    X_location = np.zeros( (len(df), len(df[key].cat.categories) ) )\n",
    "    X_location[range(len(df)), df[key].cat.codes] = X_GFA_building.ravel()\n",
    "else:\n",
    "    features_location = ['Longitude', 'Latitude']\n",
    "    X_location = df[features_location].values\n",
    "    if True:\n",
    "        X_location = np.hstack( (X_location, X_location**2) )\n",
    "        features_location += ['Longitude**2', 'Latitude**2']\n",
    "    X_location *= X_GFA_building.reshape(-1,1)\n",
    "\n",
    "\n",
    "# for verification\n",
    "# for i in range(100):\n",
    "#     print(i, df['Neighborhood'].cat.codes.values[i],  X_neighborhood[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743d457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.hstack ([X_ParkingGFA.reshape(-1,1)] + [ Xi.reshape(-1,1) * X_propotion_PropertyUseTypeGFA for Xi in X_propotion_energy.transpose()])\n",
    "\n",
    "# X_propotion_PropertyUseTypeGFA = log_transfrom( X_propotion_PropertyUseTypeGFA )\n",
    "X_propotion_energy = log_transfrom( X_propotion_energy )\n",
    "\n",
    "X_GFA_building = log_transfrom( X_GFA_building )\n",
    "X_GFA_parking = log_transfrom( X_GFA_parking )\n",
    "\n",
    "df['NumberofBuildings'] = log_transfrom( df['NumberofBuildings'] )\n",
    "df['NumberofFloors'] = log_transfrom( df['NumberofFloors'] )\n",
    "# df['YearBuilt'] = log_transfrom( df['YearBuilt'] )\n",
    "# df['YearBuilt**2'] = df['YearBuilt'].values**2\n",
    "\n",
    "# X = np.hstack ([X_GFA_parking] + [ Xi.reshape(-1,1) * X_GFA for Xi in X_propotion_energy.transpose()])\n",
    "X = np.hstack ( [X_GFA_parking]\n",
    "    + [X_GFA_building] + [X_propotion_PropertyUseTypeGFA] # * X_GFA_building.reshape(-1,1)]\n",
    "    + [X_location]\n",
    "    # + [df['Neighborhood'].astype('category').cat.codes.values.reshape(-1,1)]\n",
    "    + [X_propotion_energy] + [df[['NumberofBuildings', 'NumberofFloors','YearBuilt', 'Outlier']].values] )\n",
    "\n",
    "features_X = ['GFA_parking', 'GFA_building'] \\\n",
    "    + features_location \\\n",
    "    + PropertyUseTypes.tolist() \\\n",
    "    + features_3 + ['NumberofBuildings', 'NumberofFloors','YearBuilt', 'Outlier']\n",
    "# X[-4] = np.log( 1 + X[-4] )\n",
    "# X[-5] = np.log( 1 + X[-5] )\n",
    "\n",
    "X = np.hstack( (X, X**2))\n",
    "\n",
    "if False:\n",
    "    features_zeros = []\n",
    "    for feature in features_zeros:\n",
    "        i = features_X.index( feature )\n",
    "        X = np.delete( X, i, 1 )\n",
    "        features_X.remove( feature )\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split( X, y, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit( X_test )\n",
    "X_test = scaler.transform( X_test )\n",
    "X_train = scaler.transform( X_train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb924957",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X', X.shape)\n",
    "print( 'X_train:', X_train.shape )\n",
    "# display( len( df['Neighborhood'].value_counts() ) )\n",
    "# df['Neighborhood'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf8c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'X_parking:', X_ParkingGFA.shape )\n",
    "print( 'X_PropertyUseType:', X_propotion_PropertyUseTypeGFA.shape )\n",
    "print( 'X_propotion_energy:', X_propotion_energy.shape )\n",
    "print('features_1:\\n', features_1)\n",
    "print('\\nfeatures_2:\\n', features_2)\n",
    "print('\\nfeatures_3:\\n', features_3)\n",
    "print('\\nfeatures_4:\\n', features_4)\n",
    "print('\\nfeatures_X:\\n', features_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08420d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_results = {'y_test':y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9312f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results( label ):\n",
    "    y_test, y_pred = dico_results['y_test'], dico_results[label]['y_pred']\n",
    "\n",
    "    argsort = y_test.argsort()\n",
    "    fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "    ax.plot( y_test[argsort], 'r', label='data' )\n",
    "    ax.plot( y_pred[argsort], 'bo', markersize=2, label=label )\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('sample')\n",
    "\n",
    "    fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "    ax.plot( y_test, y_pred, 'bo', markersize=2, label=f'prediction {label}' )\n",
    "    xy_optim = [y_test.min(), y_test.max()]\n",
    "    ax.plot( xy_optim, xy_optim, 'r', label='optimal fit' )\n",
    "    ax.legend()\n",
    "    ax.set_xlabel( 'prediction ' + label)\n",
    "    imin = y_test.argmin()\n",
    "    print( y_pred[imin], y_test[imin] )\n",
    "\n",
    "    ax.set_xlabel( str_out )\n",
    "\n",
    "def model_to_results( name, model, X_test, training_time ):\n",
    "    dico_results[name] = {'y_pred': model.predict(X_test),\n",
    "                        'training time': training_time,\n",
    "                        'model':model }\n",
    "\n",
    "def print_results( ):\n",
    "    y_test = dico_results['y_test']\n",
    "    df_results = pd.DataFrame( index=['training time (sec.)', 'MSE', 'R2 score'])\n",
    "    for (name, results) in dico_results.items():\n",
    "        if name == 'y_test' :\n",
    "            continue\n",
    "        y_pred = results['y_pred']\n",
    "        df_results[name] = [results['training time'], \n",
    "                            metrics.mean_squared_error(y_test, y_pred),\n",
    "                            metrics.r2_score(y_test, y_pred) ]\n",
    "    \n",
    "    display( df_results )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1cb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize=(12*cm, 8*cm))\n",
    "ax.plot( X_propotion_PropertyUseTypeGFA.sum(1) * df['PropertyGFABuilding(s)'], y, 'bo', markersize=2 )\n",
    "ax.set_xlim([-0.5e6, 2.2e6])\n",
    "ax.set_ylim([-0.5, 22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff4357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dummy median'\n",
    "t0 = time.time()\n",
    "dr = dummy.DummyRegressor( strategy='median' ).fit( X_train, y_train )\n",
    "model_to_results( model_name, dr, X_test, time.time()-t0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88fcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results()\n",
    "plot_results( model_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lasso'\n",
    "alphas_lasso = np.logspace(-5, 0, 100)\n",
    "t0 = time.time()\n",
    "model = linear_model.LassoCV( alphas=alphas_lasso, cv=5 ).fit( X_train, y_train )\n",
    "\n",
    "model_to_results( model_name, model, X_test, time.time()-t0 )\n",
    "_, coefs_lasso, _ = linear_model.lasso_path( X_train, y_train, alphas=alphas_lasso )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb835e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_lassoCV = model.alpha_\n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print( 'alpha:', alpha_lassoCV)\n",
    "\n",
    "print_results()\n",
    "plot_results( model_name )\n",
    "\n",
    "# print( alphas_lasso.shape )\n",
    "# print(coefs_lasso.shape)\n",
    "# print(X_train.shape)\n",
    "\n",
    "# histogram_per_coef( X_train, model.cohistogram_per_coef( X, coefs, features )ef_, features_X )\n",
    "\n",
    "print_coefs( model.coef_, features_X )\n",
    "argsort = np.abs(model.coef_).argsort()\n",
    "print('\\nsorted coefs:')\n",
    "for i in argsort:\n",
    "    print( f'{features_X[i]}: { model.coef_[i]:.6f}' )\n",
    "\n",
    "print('\\nlowest coefs:')\n",
    "print('[', end='')\n",
    "for i in argsort[:-10]:\n",
    "    print( f\"'{features_X[i]}', \", end='')\n",
    "print(']')\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(20*cm,12*cm) )\n",
    "for feature, coefs in zip( features_X, coefs_lasso ):\n",
    "    ax.semilogx( alphas_lasso, coefs, label=feature)\n",
    "# ax.semilogx( alphas_lasso, coefs_lasso.transpose() )\n",
    "ax.plot( [alpha_lassoCV,]*2, [coefs_lasso.min(), coefs_lasso.max()], 'r--' )\n",
    "# ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "argsort = y_train.argsort()\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "ax.plot( y_train[argsort], 'r' )\n",
    "ax.plot( model.predict( X_train )[argsort], 'bo', markersize=2, label=model_name )\n",
    "ax.legend()\n",
    "ax.set_title('train set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help( linear_model.ElasticNet )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0748e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Elastic net'\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'l1_ratio':np.geomspace(0.5, 0.99, 10),\n",
    "            'alpha':np.logspace(-5, 1, 20)}\n",
    "\n",
    "model = train_model( model_name, linear_model.ElasticNet(random_state=0), param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(model.best_params_)\n",
    "\n",
    "print_coefs( model.best_estimator_.coef_, features_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6638eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results()\n",
    "plot_results( model_name )\n",
    "\n",
    "print( 'train MSE: {:.3f}'.format( metrics.mean_squared_error( y_train, model.predict(X_train) ) ) )\n",
    "print( 'train r2: {:.3f}'.format( metrics.r2_score( y_train, model.predict(X_train) ) ) )\n",
    "\n",
    "argsort = y_train.argsort()\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm))\n",
    "ax.plot( y_train[argsort], 'r' )\n",
    "ax.plot( model.predict( X_train )[argsort], 'bo', markersize=2, label=model_name )\n",
    "ax.legend()\n",
    "ax.set_title('train set')\n",
    "\n",
    "if False:\n",
    "    fig, ax = plt.subplots( figsize=(12*cm,8*cm))\n",
    "    ax.plot( [y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r' )\n",
    "    ax.plot( y_train, model.predict( X_train) , 'bo', markersize=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "# help( LinearSVR )\n",
    "\n",
    "model_name = 'Linear SVR'\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'loss':['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "            'C':np.logspace(-5, 10, 20)\n",
    "            }\n",
    "\n",
    "\n",
    "model = train_model( model_name, LinearSVR( dual=False ), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results()\n",
    "plot_results( model_name )\n",
    "\n",
    "argsort = y_train.argsort()\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "ax.plot( y_train[argsort], 'r' )\n",
    "ax.plot( model.predict( X_train )[argsort], 'bo', markersize=2, label=model_name )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad182b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import kernel_ridge\n",
    "\n",
    "model_name = 'Kernel ridge'\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "            'alpha':np.logspace(-4, -2, 10),\n",
    "            'gamma':np.logspace(-4, -2, 10),\n",
    "            }\n",
    "\n",
    "model = train_model( model_name, kernel_ridge.KernelRidge(kernel='rbf'), param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "print_results()\n",
    "plot_results( model_name )\n",
    "\n",
    "argsort = y_train.argsort()\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "ax.plot( y_train[argsort], 'r' )\n",
    "ax.plot( model.predict( X_train )[argsort], 'bo', markersize=2, label=model_name )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Kernel SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "help( svm.SVR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e21ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Kernel SVR'\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {\n",
    "            'C':np.logspace(0, 4, 10),\n",
    "            'gamma':np.logspace(-5, -3, 10),\n",
    "            }\n",
    "\n",
    "model = train_model( model_name, svm.SVR(kernel='rbf'), param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a1b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "print_results()\n",
    "plot_results( model_name )\n",
    "\n",
    "argsort = y_train.argsort()\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "ax.plot( y_train[argsort], 'r' )\n",
    "ax.plot( model.predict( X_train )[argsort], 'bo', markersize=2, label=model_name )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "help( RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bdbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# help( RandomForestRegressor )\n",
    "\n",
    "model_name = 'Random forest'\n",
    "param_grid = {\n",
    "    'n_estimators':[300, 400, 500],\n",
    "    'min_samples_split': [10, 20, 50],\n",
    "    'max_depth':[None, 5, 10]\n",
    "}\n",
    "\n",
    "model = train_model( model_name, RandomForestRegressor(), param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc706e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "print_results()\n",
    "plot_results( model_name )\n",
    "\n",
    "argsort = y_train.argsort()\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "ax.plot( y_train[argsort], 'r' )\n",
    "ax.plot( model.predict( X_train )[argsort], 'bo', markersize=2, label=model_name )\n",
    "ax.legend()\n",
    "ax.set_title('train set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model_name = 'Light GBM'\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 300],\n",
    "    # 'max_features': [ i  for i in range(1, X.shape[1], 10) ] + [X.shape[1]],\n",
    "    'subsample': np.arange(0.1, 1.1, 0.1),\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "    'max_depth': np.arange(2, 11, 2),\n",
    "}\n",
    "\n",
    "model = train_model( model_name, lgb.LGBMRegressor(), param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf871ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "print_results()\n",
    "plot_results( model_name )\n",
    "\n",
    "argsort = y_train.argsort()\n",
    "fig, ax = plt.subplots( figsize=(12*cm,8*cm) )\n",
    "ax.plot( y_train[argsort], 'r' )\n",
    "ax.plot( model.predict( X_train )[argsort], 'bo', markersize=2, label=model_name )\n",
    "ax.legend()\n",
    "ax.set_title('train set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10 (main, Feb  8 2023, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "494689f2acac87956b2fb49f164ea5a9a6b259eda3b61e1868bcc936735ce35f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
